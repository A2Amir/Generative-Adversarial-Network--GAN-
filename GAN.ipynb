{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                    optimizer=optimizer,\n",
    "                                    metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "        \n",
    "        print('The shape of input is:',X_train.shape)\n",
    "        print('The shape of image is:',X_train[0].shape)\n",
    "        plt.imshow(X_train[0], cmap='gray')\n",
    "        \n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as valid)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.show()\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "The shape of input is: (60000, 28, 28)\n",
      "The shape of image is: (28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.604355, acc.: 75.00%] [G loss: 0.887887]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\ipykernel_launcher.py:144: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\envs\\Huber\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: 0.304875, acc.: 90.62%] [G loss: 1.026048]\n",
      "2 [D loss: 0.233837, acc.: 95.31%] [G loss: 1.164382]\n",
      "3 [D loss: 0.206257, acc.: 98.44%] [G loss: 1.268679]\n",
      "4 [D loss: 0.137650, acc.: 100.00%] [G loss: 1.580477]\n",
      "5 [D loss: 0.141160, acc.: 100.00%] [G loss: 1.607112]\n",
      "6 [D loss: 0.134612, acc.: 100.00%] [G loss: 1.746711]\n",
      "7 [D loss: 0.115251, acc.: 100.00%] [G loss: 1.982289]\n",
      "8 [D loss: 0.101511, acc.: 100.00%] [G loss: 2.003405]\n",
      "9 [D loss: 0.088972, acc.: 100.00%] [G loss: 2.128843]\n",
      "10 [D loss: 0.070727, acc.: 100.00%] [G loss: 2.282955]\n",
      "11 [D loss: 0.062680, acc.: 100.00%] [G loss: 2.307953]\n",
      "12 [D loss: 0.075522, acc.: 100.00%] [G loss: 2.387425]\n",
      "13 [D loss: 0.052508, acc.: 100.00%] [G loss: 2.342125]\n",
      "14 [D loss: 0.057553, acc.: 100.00%] [G loss: 2.606266]\n",
      "15 [D loss: 0.055084, acc.: 100.00%] [G loss: 2.488668]\n",
      "16 [D loss: 0.053167, acc.: 100.00%] [G loss: 2.614165]\n",
      "17 [D loss: 0.040379, acc.: 100.00%] [G loss: 2.793756]\n",
      "18 [D loss: 0.035527, acc.: 100.00%] [G loss: 2.776139]\n",
      "19 [D loss: 0.036627, acc.: 100.00%] [G loss: 2.844792]\n",
      "20 [D loss: 0.044760, acc.: 100.00%] [G loss: 2.933779]\n",
      "21 [D loss: 0.039291, acc.: 100.00%] [G loss: 3.068761]\n",
      "22 [D loss: 0.034335, acc.: 100.00%] [G loss: 3.016417]\n",
      "23 [D loss: 0.031491, acc.: 100.00%] [G loss: 3.061551]\n",
      "24 [D loss: 0.027416, acc.: 100.00%] [G loss: 3.201333]\n",
      "25 [D loss: 0.033001, acc.: 100.00%] [G loss: 3.177230]\n",
      "26 [D loss: 0.028556, acc.: 100.00%] [G loss: 3.115748]\n",
      "27 [D loss: 0.024270, acc.: 100.00%] [G loss: 3.288164]\n",
      "28 [D loss: 0.022802, acc.: 100.00%] [G loss: 3.224856]\n",
      "29 [D loss: 0.026732, acc.: 100.00%] [G loss: 3.249769]\n",
      "30 [D loss: 0.030654, acc.: 100.00%] [G loss: 3.304249]\n",
      "31 [D loss: 0.024618, acc.: 100.00%] [G loss: 3.454505]\n",
      "32 [D loss: 0.026962, acc.: 100.00%] [G loss: 3.382339]\n",
      "33 [D loss: 0.023309, acc.: 100.00%] [G loss: 3.611764]\n",
      "34 [D loss: 0.022126, acc.: 100.00%] [G loss: 3.600302]\n",
      "35 [D loss: 0.020526, acc.: 100.00%] [G loss: 3.598596]\n",
      "36 [D loss: 0.016313, acc.: 100.00%] [G loss: 3.543001]\n",
      "37 [D loss: 0.028097, acc.: 100.00%] [G loss: 3.597582]\n",
      "38 [D loss: 0.019821, acc.: 100.00%] [G loss: 3.827282]\n",
      "39 [D loss: 0.017385, acc.: 100.00%] [G loss: 3.734771]\n",
      "40 [D loss: 0.013339, acc.: 100.00%] [G loss: 3.770515]\n",
      "41 [D loss: 0.015279, acc.: 100.00%] [G loss: 3.863602]\n",
      "42 [D loss: 0.019036, acc.: 100.00%] [G loss: 3.832479]\n",
      "43 [D loss: 0.016842, acc.: 100.00%] [G loss: 3.980978]\n",
      "44 [D loss: 0.015811, acc.: 100.00%] [G loss: 3.907345]\n",
      "45 [D loss: 0.021418, acc.: 100.00%] [G loss: 3.938473]\n",
      "46 [D loss: 0.015937, acc.: 100.00%] [G loss: 3.921079]\n",
      "47 [D loss: 0.019379, acc.: 100.00%] [G loss: 3.988223]\n",
      "48 [D loss: 0.018000, acc.: 100.00%] [G loss: 4.234110]\n",
      "49 [D loss: 0.016483, acc.: 100.00%] [G loss: 4.162095]\n",
      "50 [D loss: 0.012096, acc.: 100.00%] [G loss: 4.294793]\n",
      "51 [D loss: 0.013778, acc.: 100.00%] [G loss: 4.117608]\n",
      "52 [D loss: 0.015956, acc.: 100.00%] [G loss: 4.240887]\n",
      "53 [D loss: 0.012374, acc.: 100.00%] [G loss: 4.179816]\n",
      "54 [D loss: 0.010398, acc.: 100.00%] [G loss: 4.032816]\n",
      "55 [D loss: 0.011832, acc.: 100.00%] [G loss: 4.203899]\n",
      "56 [D loss: 0.011185, acc.: 100.00%] [G loss: 4.188043]\n",
      "57 [D loss: 0.012081, acc.: 100.00%] [G loss: 4.175342]\n",
      "58 [D loss: 0.017057, acc.: 100.00%] [G loss: 4.190304]\n",
      "59 [D loss: 0.012508, acc.: 100.00%] [G loss: 4.166561]\n",
      "60 [D loss: 0.011783, acc.: 100.00%] [G loss: 4.144001]\n",
      "61 [D loss: 0.013708, acc.: 100.00%] [G loss: 4.221472]\n",
      "62 [D loss: 0.009416, acc.: 100.00%] [G loss: 4.243494]\n",
      "63 [D loss: 0.011205, acc.: 100.00%] [G loss: 4.495542]\n",
      "64 [D loss: 0.013230, acc.: 100.00%] [G loss: 4.296227]\n",
      "65 [D loss: 0.015519, acc.: 100.00%] [G loss: 4.498733]\n",
      "66 [D loss: 0.009209, acc.: 100.00%] [G loss: 4.294560]\n",
      "67 [D loss: 0.014228, acc.: 100.00%] [G loss: 4.443520]\n",
      "68 [D loss: 0.018955, acc.: 100.00%] [G loss: 4.471502]\n",
      "69 [D loss: 0.008618, acc.: 100.00%] [G loss: 4.541804]\n",
      "70 [D loss: 0.009935, acc.: 100.00%] [G loss: 4.448664]\n",
      "71 [D loss: 0.010101, acc.: 100.00%] [G loss: 4.467834]\n",
      "72 [D loss: 0.012074, acc.: 100.00%] [G loss: 4.565895]\n",
      "73 [D loss: 0.009670, acc.: 100.00%] [G loss: 4.397166]\n",
      "74 [D loss: 0.011821, acc.: 100.00%] [G loss: 4.416931]\n",
      "75 [D loss: 0.014931, acc.: 100.00%] [G loss: 4.658548]\n",
      "76 [D loss: 0.010536, acc.: 100.00%] [G loss: 4.684699]\n",
      "77 [D loss: 0.012456, acc.: 100.00%] [G loss: 4.697020]\n",
      "78 [D loss: 0.015540, acc.: 100.00%] [G loss: 4.856726]\n",
      "79 [D loss: 0.009148, acc.: 100.00%] [G loss: 4.721313]\n",
      "80 [D loss: 0.008633, acc.: 100.00%] [G loss: 4.672834]\n",
      "81 [D loss: 0.010421, acc.: 100.00%] [G loss: 4.558154]\n",
      "82 [D loss: 0.013315, acc.: 100.00%] [G loss: 4.680337]\n",
      "83 [D loss: 0.008327, acc.: 100.00%] [G loss: 4.642901]\n",
      "84 [D loss: 0.011467, acc.: 100.00%] [G loss: 4.782742]\n",
      "85 [D loss: 0.012280, acc.: 100.00%] [G loss: 4.827303]\n",
      "86 [D loss: 0.008619, acc.: 100.00%] [G loss: 4.584918]\n",
      "87 [D loss: 0.019101, acc.: 100.00%] [G loss: 4.866944]\n",
      "88 [D loss: 0.010362, acc.: 100.00%] [G loss: 5.068172]\n",
      "89 [D loss: 0.010092, acc.: 100.00%] [G loss: 4.794716]\n",
      "90 [D loss: 0.009773, acc.: 100.00%] [G loss: 4.858642]\n",
      "91 [D loss: 0.010885, acc.: 100.00%] [G loss: 4.892902]\n",
      "92 [D loss: 0.010394, acc.: 100.00%] [G loss: 4.776978]\n",
      "93 [D loss: 0.009427, acc.: 100.00%] [G loss: 4.699777]\n",
      "94 [D loss: 0.009192, acc.: 100.00%] [G loss: 4.747450]\n",
      "95 [D loss: 0.012669, acc.: 100.00%] [G loss: 4.882323]\n",
      "96 [D loss: 0.008623, acc.: 100.00%] [G loss: 4.812402]\n",
      "97 [D loss: 0.010640, acc.: 100.00%] [G loss: 5.220534]\n",
      "98 [D loss: 0.008955, acc.: 100.00%] [G loss: 4.960762]\n",
      "99 [D loss: 0.012371, acc.: 100.00%] [G loss: 5.053918]\n",
      "100 [D loss: 0.015466, acc.: 100.00%] [G loss: 5.029763]\n",
      "101 [D loss: 0.010332, acc.: 100.00%] [G loss: 5.075488]\n",
      "102 [D loss: 0.008594, acc.: 100.00%] [G loss: 5.083076]\n",
      "103 [D loss: 0.015599, acc.: 100.00%] [G loss: 4.965110]\n",
      "104 [D loss: 0.011760, acc.: 100.00%] [G loss: 5.085986]\n",
      "105 [D loss: 0.013061, acc.: 100.00%] [G loss: 5.118026]\n",
      "106 [D loss: 0.027372, acc.: 100.00%] [G loss: 5.429354]\n",
      "107 [D loss: 0.011822, acc.: 100.00%] [G loss: 5.417470]\n",
      "108 [D loss: 0.014947, acc.: 100.00%] [G loss: 5.459734]\n",
      "109 [D loss: 0.015821, acc.: 100.00%] [G loss: 5.305796]\n",
      "110 [D loss: 0.018721, acc.: 100.00%] [G loss: 5.181757]\n",
      "111 [D loss: 0.010795, acc.: 100.00%] [G loss: 5.223847]\n",
      "112 [D loss: 0.013923, acc.: 100.00%] [G loss: 5.015754]\n",
      "113 [D loss: 0.010160, acc.: 100.00%] [G loss: 5.051118]\n",
      "114 [D loss: 0.023407, acc.: 100.00%] [G loss: 5.585315]\n",
      "115 [D loss: 0.047534, acc.: 98.44%] [G loss: 5.511067]\n",
      "116 [D loss: 0.042425, acc.: 100.00%] [G loss: 5.310385]\n",
      "117 [D loss: 0.040685, acc.: 100.00%] [G loss: 5.824957]\n",
      "118 [D loss: 0.083744, acc.: 96.88%] [G loss: 4.279461]\n",
      "119 [D loss: 0.086447, acc.: 98.44%] [G loss: 5.601964]\n",
      "120 [D loss: 0.015002, acc.: 100.00%] [G loss: 6.615338]\n",
      "121 [D loss: 0.184851, acc.: 92.19%] [G loss: 4.136766]\n",
      "122 [D loss: 0.299327, acc.: 84.38%] [G loss: 5.567430]\n",
      "123 [D loss: 0.011915, acc.: 100.00%] [G loss: 7.187276]\n",
      "124 [D loss: 0.329422, acc.: 89.06%] [G loss: 3.843015]\n",
      "125 [D loss: 0.229839, acc.: 89.06%] [G loss: 4.114869]\n",
      "126 [D loss: 0.150414, acc.: 90.62%] [G loss: 5.592088]\n",
      "127 [D loss: 0.022795, acc.: 98.44%] [G loss: 6.264009]\n",
      "128 [D loss: 0.030294, acc.: 100.00%] [G loss: 6.131345]\n",
      "129 [D loss: 0.033351, acc.: 98.44%] [G loss: 5.916751]\n",
      "130 [D loss: 0.037767, acc.: 100.00%] [G loss: 5.284500]\n",
      "131 [D loss: 0.112828, acc.: 92.19%] [G loss: 4.602814]\n",
      "132 [D loss: 0.096484, acc.: 95.31%] [G loss: 5.491937]\n",
      "133 [D loss: 0.222886, acc.: 90.62%] [G loss: 3.735357]\n",
      "134 [D loss: 0.116837, acc.: 95.31%] [G loss: 4.462999]\n",
      "135 [D loss: 0.034486, acc.: 100.00%] [G loss: 5.156282]\n",
      "136 [D loss: 0.184731, acc.: 90.62%] [G loss: 4.762913]\n",
      "137 [D loss: 0.072078, acc.: 96.88%] [G loss: 4.754138]\n",
      "138 [D loss: 0.092683, acc.: 96.88%] [G loss: 4.268767]\n",
      "139 [D loss: 0.286756, acc.: 87.50%] [G loss: 5.362738]\n",
      "140 [D loss: 0.552749, acc.: 75.00%] [G loss: 2.562689]\n",
      "141 [D loss: 0.875685, acc.: 73.44%] [G loss: 3.006836]\n",
      "142 [D loss: 0.114117, acc.: 96.88%] [G loss: 4.491435]\n",
      "143 [D loss: 0.064683, acc.: 96.88%] [G loss: 4.673421]\n",
      "144 [D loss: 0.117104, acc.: 96.88%] [G loss: 4.121610]\n",
      "145 [D loss: 0.057157, acc.: 100.00%] [G loss: 4.468916]\n",
      "146 [D loss: 0.046004, acc.: 100.00%] [G loss: 3.967941]\n",
      "147 [D loss: 0.088037, acc.: 98.44%] [G loss: 4.126295]\n",
      "148 [D loss: 0.066870, acc.: 98.44%] [G loss: 4.232218]\n",
      "149 [D loss: 0.156438, acc.: 93.75%] [G loss: 3.812784]\n",
      "150 [D loss: 0.074745, acc.: 98.44%] [G loss: 4.208056]\n",
      "151 [D loss: 0.271161, acc.: 90.62%] [G loss: 3.875838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 [D loss: 0.158482, acc.: 93.75%] [G loss: 4.927790]\n",
      "153 [D loss: 0.713310, acc.: 73.44%] [G loss: 2.904322]\n",
      "154 [D loss: 0.256942, acc.: 84.38%] [G loss: 3.754420]\n",
      "155 [D loss: 0.076567, acc.: 96.88%] [G loss: 5.014224]\n",
      "156 [D loss: 0.174882, acc.: 92.19%] [G loss: 3.535757]\n",
      "157 [D loss: 0.189544, acc.: 90.62%] [G loss: 3.997175]\n",
      "158 [D loss: 0.060967, acc.: 98.44%] [G loss: 4.656843]\n",
      "159 [D loss: 0.188410, acc.: 96.88%] [G loss: 3.955621]\n",
      "160 [D loss: 0.067929, acc.: 98.44%] [G loss: 4.228832]\n",
      "161 [D loss: 0.223973, acc.: 89.06%] [G loss: 3.231294]\n",
      "162 [D loss: 0.101134, acc.: 98.44%] [G loss: 4.227292]\n",
      "163 [D loss: 0.253334, acc.: 92.19%] [G loss: 3.488127]\n",
      "164 [D loss: 0.085499, acc.: 98.44%] [G loss: 4.086636]\n",
      "165 [D loss: 0.545455, acc.: 73.44%] [G loss: 2.899199]\n",
      "166 [D loss: 0.104240, acc.: 96.88%] [G loss: 3.854068]\n",
      "167 [D loss: 0.189267, acc.: 93.75%] [G loss: 3.707870]\n",
      "168 [D loss: 0.105997, acc.: 100.00%] [G loss: 3.534738]\n",
      "169 [D loss: 0.125109, acc.: 100.00%] [G loss: 3.452301]\n",
      "170 [D loss: 0.131642, acc.: 96.88%] [G loss: 4.078449]\n",
      "171 [D loss: 0.664370, acc.: 70.31%] [G loss: 2.627584]\n",
      "172 [D loss: 0.149974, acc.: 92.19%] [G loss: 4.037931]\n",
      "173 [D loss: 0.053613, acc.: 100.00%] [G loss: 4.215079]\n",
      "174 [D loss: 0.169537, acc.: 95.31%] [G loss: 3.018366]\n",
      "175 [D loss: 0.156000, acc.: 92.19%] [G loss: 4.058155]\n",
      "176 [D loss: 0.182920, acc.: 95.31%] [G loss: 3.878656]\n",
      "177 [D loss: 0.194581, acc.: 90.62%] [G loss: 3.209010]\n",
      "178 [D loss: 0.074360, acc.: 100.00%] [G loss: 3.968737]\n",
      "179 [D loss: 0.102985, acc.: 100.00%] [G loss: 3.567814]\n",
      "180 [D loss: 0.170476, acc.: 89.06%] [G loss: 4.270800]\n",
      "181 [D loss: 0.400279, acc.: 81.25%] [G loss: 3.275360]\n",
      "182 [D loss: 0.115435, acc.: 95.31%] [G loss: 4.929485]\n",
      "183 [D loss: 0.928996, acc.: 57.81%] [G loss: 1.694300]\n",
      "184 [D loss: 0.544306, acc.: 75.00%] [G loss: 2.117041]\n",
      "185 [D loss: 0.075995, acc.: 98.44%] [G loss: 4.193114]\n",
      "186 [D loss: 0.043318, acc.: 100.00%] [G loss: 4.260541]\n",
      "187 [D loss: 0.134781, acc.: 95.31%] [G loss: 3.330302]\n",
      "188 [D loss: 0.123499, acc.: 96.88%] [G loss: 3.824075]\n",
      "189 [D loss: 0.084656, acc.: 98.44%] [G loss: 3.994276]\n",
      "190 [D loss: 0.214613, acc.: 92.19%] [G loss: 3.455410]\n",
      "191 [D loss: 0.124700, acc.: 98.44%] [G loss: 3.148455]\n",
      "192 [D loss: 0.114754, acc.: 98.44%] [G loss: 3.268646]\n",
      "193 [D loss: 0.125773, acc.: 98.44%] [G loss: 3.254053]\n",
      "194 [D loss: 0.203945, acc.: 90.62%] [G loss: 3.482546]\n",
      "195 [D loss: 0.365205, acc.: 81.25%] [G loss: 3.903696]\n",
      "196 [D loss: 1.059161, acc.: 53.12%] [G loss: 2.578566]\n",
      "197 [D loss: 0.140510, acc.: 93.75%] [G loss: 3.916900]\n",
      "198 [D loss: 0.435472, acc.: 73.44%] [G loss: 3.476122]\n",
      "199 [D loss: 0.097990, acc.: 100.00%] [G loss: 4.115623]\n",
      "200 [D loss: 0.215929, acc.: 92.19%] [G loss: 2.933204]\n",
      "201 [D loss: 0.217174, acc.: 89.06%] [G loss: 4.513866]\n",
      "202 [D loss: 0.808872, acc.: 64.06%] [G loss: 2.098553]\n",
      "203 [D loss: 0.173579, acc.: 92.19%] [G loss: 3.699757]\n",
      "204 [D loss: 0.160648, acc.: 96.88%] [G loss: 3.094249]\n",
      "205 [D loss: 0.438860, acc.: 81.25%] [G loss: 2.943723]\n",
      "206 [D loss: 0.120193, acc.: 96.88%] [G loss: 4.635390]\n",
      "207 [D loss: 0.761569, acc.: 60.94%] [G loss: 2.260670]\n",
      "208 [D loss: 0.147896, acc.: 96.88%] [G loss: 4.106943]\n",
      "209 [D loss: 0.296320, acc.: 85.94%] [G loss: 3.322516]\n",
      "210 [D loss: 0.149388, acc.: 95.31%] [G loss: 3.352899]\n",
      "211 [D loss: 0.337280, acc.: 84.38%] [G loss: 3.126275]\n",
      "212 [D loss: 0.162569, acc.: 96.88%] [G loss: 3.823495]\n",
      "213 [D loss: 0.403362, acc.: 79.69%] [G loss: 2.495701]\n",
      "214 [D loss: 0.150216, acc.: 93.75%] [G loss: 4.115508]\n",
      "215 [D loss: 0.909771, acc.: 59.38%] [G loss: 1.755093]\n",
      "216 [D loss: 0.230322, acc.: 90.62%] [G loss: 3.494909]\n",
      "217 [D loss: 0.541519, acc.: 68.75%] [G loss: 2.076979]\n",
      "218 [D loss: 0.178850, acc.: 96.88%] [G loss: 3.601567]\n",
      "219 [D loss: 0.252866, acc.: 95.31%] [G loss: 2.854826]\n",
      "220 [D loss: 0.499832, acc.: 75.00%] [G loss: 3.447175]\n",
      "221 [D loss: 0.309503, acc.: 95.31%] [G loss: 3.077092]\n",
      "222 [D loss: 0.280961, acc.: 92.19%] [G loss: 3.795354]\n",
      "223 [D loss: 1.065125, acc.: 50.00%] [G loss: 2.063194]\n",
      "224 [D loss: 0.236145, acc.: 90.62%] [G loss: 3.763244]\n",
      "225 [D loss: 0.477150, acc.: 78.12%] [G loss: 2.336668]\n",
      "226 [D loss: 0.257476, acc.: 89.06%] [G loss: 3.658040]\n",
      "227 [D loss: 0.784773, acc.: 53.12%] [G loss: 2.350579]\n",
      "228 [D loss: 0.198057, acc.: 95.31%] [G loss: 3.961024]\n",
      "229 [D loss: 1.013156, acc.: 40.62%] [G loss: 1.219333]\n",
      "230 [D loss: 0.522199, acc.: 65.62%] [G loss: 2.748500]\n",
      "231 [D loss: 0.356724, acc.: 90.62%] [G loss: 2.877386]\n",
      "232 [D loss: 0.386764, acc.: 78.12%] [G loss: 2.653602]\n",
      "233 [D loss: 0.261456, acc.: 92.19%] [G loss: 2.887168]\n",
      "234 [D loss: 0.353628, acc.: 90.62%] [G loss: 2.464477]\n",
      "235 [D loss: 0.432037, acc.: 73.44%] [G loss: 2.618990]\n",
      "236 [D loss: 0.517721, acc.: 71.88%] [G loss: 2.557698]\n",
      "237 [D loss: 0.354967, acc.: 82.81%] [G loss: 2.915179]\n",
      "238 [D loss: 0.893455, acc.: 45.31%] [G loss: 1.412961]\n",
      "239 [D loss: 0.275688, acc.: 84.38%] [G loss: 3.325427]\n",
      "240 [D loss: 0.556904, acc.: 65.62%] [G loss: 2.436704]\n",
      "241 [D loss: 0.221708, acc.: 95.31%] [G loss: 3.174783]\n",
      "242 [D loss: 0.495316, acc.: 79.69%] [G loss: 2.892949]\n",
      "243 [D loss: 0.811362, acc.: 56.25%] [G loss: 1.543488]\n",
      "244 [D loss: 0.280456, acc.: 85.94%] [G loss: 3.314445]\n",
      "245 [D loss: 0.774717, acc.: 51.56%] [G loss: 1.378873]\n",
      "246 [D loss: 0.351016, acc.: 82.81%] [G loss: 2.647321]\n",
      "247 [D loss: 0.624195, acc.: 65.62%] [G loss: 1.830059]\n",
      "248 [D loss: 0.365620, acc.: 82.81%] [G loss: 3.127517]\n",
      "249 [D loss: 1.151506, acc.: 31.25%] [G loss: 0.723665]\n",
      "250 [D loss: 0.497663, acc.: 62.50%] [G loss: 2.372349]\n",
      "251 [D loss: 0.659302, acc.: 62.50%] [G loss: 1.839161]\n",
      "252 [D loss: 0.528441, acc.: 68.75%] [G loss: 1.703456]\n",
      "253 [D loss: 0.554057, acc.: 64.06%] [G loss: 1.955117]\n",
      "254 [D loss: 0.706436, acc.: 57.81%] [G loss: 1.602004]\n",
      "255 [D loss: 0.417411, acc.: 84.38%] [G loss: 2.351751]\n",
      "256 [D loss: 0.849609, acc.: 51.56%] [G loss: 1.228186]\n",
      "257 [D loss: 0.524616, acc.: 65.62%] [G loss: 2.352820]\n",
      "258 [D loss: 0.839741, acc.: 46.88%] [G loss: 1.045298]\n",
      "259 [D loss: 0.452395, acc.: 70.31%] [G loss: 2.145890]\n",
      "260 [D loss: 0.952125, acc.: 34.38%] [G loss: 1.081005]\n",
      "261 [D loss: 0.510918, acc.: 65.62%] [G loss: 1.736180]\n",
      "262 [D loss: 0.664622, acc.: 59.38%] [G loss: 1.659007]\n",
      "263 [D loss: 0.778291, acc.: 45.31%] [G loss: 1.276311]\n",
      "264 [D loss: 0.521251, acc.: 70.31%] [G loss: 2.053386]\n",
      "265 [D loss: 0.987752, acc.: 29.69%] [G loss: 0.945506]\n",
      "266 [D loss: 0.595151, acc.: 62.50%] [G loss: 1.815576]\n",
      "267 [D loss: 0.687018, acc.: 60.94%] [G loss: 1.553193]\n",
      "268 [D loss: 0.875748, acc.: 39.06%] [G loss: 0.944490]\n",
      "269 [D loss: 0.536459, acc.: 64.06%] [G loss: 1.752333]\n",
      "270 [D loss: 0.945534, acc.: 32.81%] [G loss: 0.860200]\n",
      "271 [D loss: 0.575228, acc.: 56.25%] [G loss: 1.388071]\n",
      "272 [D loss: 0.699229, acc.: 48.44%] [G loss: 1.414619]\n",
      "273 [D loss: 0.642686, acc.: 65.62%] [G loss: 1.192944]\n",
      "274 [D loss: 0.723589, acc.: 42.19%] [G loss: 1.046494]\n",
      "275 [D loss: 0.604874, acc.: 62.50%] [G loss: 1.377296]\n",
      "276 [D loss: 0.872573, acc.: 43.75%] [G loss: 0.929378]\n",
      "277 [D loss: 0.621048, acc.: 62.50%] [G loss: 1.134672]\n",
      "278 [D loss: 0.820362, acc.: 37.50%] [G loss: 0.869418]\n",
      "279 [D loss: 0.686814, acc.: 53.12%] [G loss: 0.958823]\n",
      "280 [D loss: 0.764805, acc.: 40.62%] [G loss: 0.856882]\n",
      "281 [D loss: 0.597534, acc.: 68.75%] [G loss: 1.122769]\n",
      "282 [D loss: 0.799792, acc.: 39.06%] [G loss: 0.907672]\n",
      "283 [D loss: 0.679998, acc.: 53.12%] [G loss: 1.006814]\n",
      "284 [D loss: 0.681724, acc.: 56.25%] [G loss: 0.958124]\n",
      "285 [D loss: 0.780339, acc.: 46.88%] [G loss: 0.849450]\n",
      "286 [D loss: 0.807497, acc.: 43.75%] [G loss: 0.738313]\n",
      "287 [D loss: 0.783105, acc.: 32.81%] [G loss: 0.724055]\n",
      "288 [D loss: 0.731271, acc.: 43.75%] [G loss: 0.813284]\n",
      "289 [D loss: 0.647685, acc.: 60.94%] [G loss: 0.936837]\n",
      "290 [D loss: 0.698821, acc.: 50.00%] [G loss: 0.895816]\n",
      "291 [D loss: 0.663981, acc.: 54.69%] [G loss: 0.847976]\n",
      "292 [D loss: 0.764477, acc.: 37.50%] [G loss: 0.786361]\n",
      "293 [D loss: 0.746967, acc.: 40.62%] [G loss: 0.843008]\n",
      "294 [D loss: 0.657453, acc.: 54.69%] [G loss: 0.843120]\n",
      "295 [D loss: 0.717702, acc.: 48.44%] [G loss: 0.762101]\n",
      "296 [D loss: 0.761014, acc.: 43.75%] [G loss: 0.740395]\n",
      "297 [D loss: 0.706603, acc.: 45.31%] [G loss: 0.812802]\n",
      "298 [D loss: 0.710605, acc.: 45.31%] [G loss: 0.790524]\n",
      "299 [D loss: 0.697708, acc.: 42.19%] [G loss: 0.784751]\n",
      "300 [D loss: 0.730708, acc.: 43.75%] [G loss: 0.813621]\n",
      "301 [D loss: 0.727926, acc.: 40.62%] [G loss: 0.765482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 [D loss: 0.729264, acc.: 46.88%] [G loss: 0.750877]\n",
      "303 [D loss: 0.698556, acc.: 45.31%] [G loss: 0.737892]\n",
      "304 [D loss: 0.772673, acc.: 35.94%] [G loss: 0.722089]\n",
      "305 [D loss: 0.671528, acc.: 54.69%] [G loss: 0.801854]\n",
      "306 [D loss: 0.647831, acc.: 57.81%] [G loss: 0.781645]\n",
      "307 [D loss: 0.741034, acc.: 29.69%] [G loss: 0.733572]\n",
      "308 [D loss: 0.695441, acc.: 43.75%] [G loss: 0.744729]\n",
      "309 [D loss: 0.675791, acc.: 46.88%] [G loss: 0.801335]\n",
      "310 [D loss: 0.701042, acc.: 50.00%] [G loss: 0.806027]\n",
      "311 [D loss: 0.669896, acc.: 50.00%] [G loss: 0.823002]\n",
      "312 [D loss: 0.651022, acc.: 57.81%] [G loss: 0.776177]\n",
      "313 [D loss: 0.649003, acc.: 51.56%] [G loss: 0.759913]\n",
      "314 [D loss: 0.685236, acc.: 48.44%] [G loss: 0.805768]\n",
      "315 [D loss: 0.625833, acc.: 53.12%] [G loss: 0.822036]\n",
      "316 [D loss: 0.695916, acc.: 42.19%] [G loss: 0.801754]\n",
      "317 [D loss: 0.744561, acc.: 32.81%] [G loss: 0.719045]\n",
      "318 [D loss: 0.664311, acc.: 45.31%] [G loss: 0.774393]\n",
      "319 [D loss: 0.703620, acc.: 46.88%] [G loss: 0.746871]\n",
      "320 [D loss: 0.714268, acc.: 35.94%] [G loss: 0.724692]\n",
      "321 [D loss: 0.696546, acc.: 46.88%] [G loss: 0.717603]\n",
      "322 [D loss: 0.630691, acc.: 53.12%] [G loss: 0.749613]\n",
      "323 [D loss: 0.696990, acc.: 42.19%] [G loss: 0.738314]\n",
      "324 [D loss: 0.683643, acc.: 42.19%] [G loss: 0.708695]\n",
      "325 [D loss: 0.703283, acc.: 42.19%] [G loss: 0.724833]\n",
      "326 [D loss: 0.678240, acc.: 46.88%] [G loss: 0.724166]\n",
      "327 [D loss: 0.666833, acc.: 46.88%] [G loss: 0.743113]\n",
      "328 [D loss: 0.652632, acc.: 46.88%] [G loss: 0.770296]\n",
      "329 [D loss: 0.690152, acc.: 45.31%] [G loss: 0.728858]\n",
      "330 [D loss: 0.687595, acc.: 42.19%] [G loss: 0.706900]\n",
      "331 [D loss: 0.672093, acc.: 43.75%] [G loss: 0.725739]\n",
      "332 [D loss: 0.689637, acc.: 43.75%] [G loss: 0.737351]\n",
      "333 [D loss: 0.677901, acc.: 48.44%] [G loss: 0.717589]\n",
      "334 [D loss: 0.668564, acc.: 46.88%] [G loss: 0.688720]\n",
      "335 [D loss: 0.656013, acc.: 50.00%] [G loss: 0.702362]\n",
      "336 [D loss: 0.669110, acc.: 50.00%] [G loss: 0.695921]\n",
      "337 [D loss: 0.664016, acc.: 43.75%] [G loss: 0.705454]\n",
      "338 [D loss: 0.653015, acc.: 46.88%] [G loss: 0.736752]\n",
      "339 [D loss: 0.652502, acc.: 59.38%] [G loss: 0.738024]\n",
      "340 [D loss: 0.683215, acc.: 45.31%] [G loss: 0.739722]\n",
      "341 [D loss: 0.650223, acc.: 50.00%] [G loss: 0.743568]\n",
      "342 [D loss: 0.679091, acc.: 46.88%] [G loss: 0.727293]\n",
      "343 [D loss: 0.661389, acc.: 46.88%] [G loss: 0.696609]\n",
      "344 [D loss: 0.647384, acc.: 51.56%] [G loss: 0.748516]\n",
      "345 [D loss: 0.661243, acc.: 46.88%] [G loss: 0.714295]\n",
      "346 [D loss: 0.684566, acc.: 43.75%] [G loss: 0.672694]\n",
      "347 [D loss: 0.645412, acc.: 45.31%] [G loss: 0.674879]\n",
      "348 [D loss: 0.645843, acc.: 51.56%] [G loss: 0.704441]\n",
      "349 [D loss: 0.674884, acc.: 46.88%] [G loss: 0.715066]\n",
      "350 [D loss: 0.675042, acc.: 40.62%] [G loss: 0.712022]\n",
      "351 [D loss: 0.663204, acc.: 48.44%] [G loss: 0.671178]\n",
      "352 [D loss: 0.678576, acc.: 43.75%] [G loss: 0.675673]\n",
      "353 [D loss: 0.656624, acc.: 45.31%] [G loss: 0.699105]\n",
      "354 [D loss: 0.675023, acc.: 48.44%] [G loss: 0.700760]\n",
      "355 [D loss: 0.642703, acc.: 51.56%] [G loss: 0.707639]\n",
      "356 [D loss: 0.685818, acc.: 48.44%] [G loss: 0.723967]\n",
      "357 [D loss: 0.678558, acc.: 53.12%] [G loss: 0.707265]\n",
      "358 [D loss: 0.658172, acc.: 53.12%] [G loss: 0.742308]\n",
      "359 [D loss: 0.654273, acc.: 60.94%] [G loss: 0.715602]\n",
      "360 [D loss: 0.684062, acc.: 48.44%] [G loss: 0.705821]\n",
      "361 [D loss: 0.695881, acc.: 43.75%] [G loss: 0.714207]\n",
      "362 [D loss: 0.647609, acc.: 50.00%] [G loss: 0.713476]\n",
      "363 [D loss: 0.669895, acc.: 50.00%] [G loss: 0.679265]\n",
      "364 [D loss: 0.676647, acc.: 51.56%] [G loss: 0.655915]\n",
      "365 [D loss: 0.687533, acc.: 50.00%] [G loss: 0.671911]\n",
      "366 [D loss: 0.666476, acc.: 46.88%] [G loss: 0.684526]\n",
      "367 [D loss: 0.676147, acc.: 50.00%] [G loss: 0.690167]\n",
      "368 [D loss: 0.673419, acc.: 53.12%] [G loss: 0.680113]\n",
      "369 [D loss: 0.653734, acc.: 59.38%] [G loss: 0.713907]\n",
      "370 [D loss: 0.666917, acc.: 50.00%] [G loss: 0.716003]\n",
      "371 [D loss: 0.667290, acc.: 53.12%] [G loss: 0.731641]\n",
      "372 [D loss: 0.689869, acc.: 48.44%] [G loss: 0.703371]\n",
      "373 [D loss: 0.690315, acc.: 46.88%] [G loss: 0.707629]\n",
      "374 [D loss: 0.689892, acc.: 42.19%] [G loss: 0.684759]\n",
      "375 [D loss: 0.676211, acc.: 53.12%] [G loss: 0.690553]\n",
      "376 [D loss: 0.680100, acc.: 48.44%] [G loss: 0.691062]\n",
      "377 [D loss: 0.673706, acc.: 53.12%] [G loss: 0.702656]\n",
      "378 [D loss: 0.678904, acc.: 53.12%] [G loss: 0.708138]\n",
      "379 [D loss: 0.678296, acc.: 46.88%] [G loss: 0.712853]\n",
      "380 [D loss: 0.691363, acc.: 43.75%] [G loss: 0.670209]\n",
      "381 [D loss: 0.668732, acc.: 50.00%] [G loss: 0.682088]\n",
      "382 [D loss: 0.659813, acc.: 56.25%] [G loss: 0.698409]\n",
      "383 [D loss: 0.649821, acc.: 50.00%] [G loss: 0.705994]\n",
      "384 [D loss: 0.656589, acc.: 50.00%] [G loss: 0.700674]\n",
      "385 [D loss: 0.662148, acc.: 51.56%] [G loss: 0.682622]\n",
      "386 [D loss: 0.655385, acc.: 53.12%] [G loss: 0.677405]\n",
      "387 [D loss: 0.665094, acc.: 46.88%] [G loss: 0.690599]\n",
      "388 [D loss: 0.669439, acc.: 45.31%] [G loss: 0.696275]\n",
      "389 [D loss: 0.662103, acc.: 54.69%] [G loss: 0.700694]\n",
      "390 [D loss: 0.657232, acc.: 51.56%] [G loss: 0.705507]\n",
      "391 [D loss: 0.661833, acc.: 48.44%] [G loss: 0.694005]\n",
      "392 [D loss: 0.666529, acc.: 45.31%] [G loss: 0.684364]\n",
      "393 [D loss: 0.665168, acc.: 53.12%] [G loss: 0.682925]\n",
      "394 [D loss: 0.663532, acc.: 43.75%] [G loss: 0.700112]\n",
      "395 [D loss: 0.659292, acc.: 53.12%] [G loss: 0.677529]\n",
      "396 [D loss: 0.657389, acc.: 54.69%] [G loss: 0.708763]\n",
      "397 [D loss: 0.664090, acc.: 53.12%] [G loss: 0.686868]\n",
      "398 [D loss: 0.671919, acc.: 48.44%] [G loss: 0.672387]\n",
      "399 [D loss: 0.661314, acc.: 48.44%] [G loss: 0.671358]\n",
      "400 [D loss: 0.688197, acc.: 43.75%] [G loss: 0.699757]\n",
      "401 [D loss: 0.673901, acc.: 54.69%] [G loss: 0.692879]\n",
      "402 [D loss: 0.645874, acc.: 56.25%] [G loss: 0.697444]\n",
      "403 [D loss: 0.675430, acc.: 54.69%] [G loss: 0.681373]\n",
      "404 [D loss: 0.656328, acc.: 48.44%] [G loss: 0.690825]\n",
      "405 [D loss: 0.667174, acc.: 48.44%] [G loss: 0.697581]\n",
      "406 [D loss: 0.656890, acc.: 50.00%] [G loss: 0.677174]\n",
      "407 [D loss: 0.665437, acc.: 56.25%] [G loss: 0.693740]\n",
      "408 [D loss: 0.645899, acc.: 54.69%] [G loss: 0.716111]\n",
      "409 [D loss: 0.665412, acc.: 50.00%] [G loss: 0.720548]\n",
      "410 [D loss: 0.677005, acc.: 45.31%] [G loss: 0.695429]\n",
      "411 [D loss: 0.670146, acc.: 57.81%] [G loss: 0.696210]\n",
      "412 [D loss: 0.661421, acc.: 56.25%] [G loss: 0.706723]\n",
      "413 [D loss: 0.663757, acc.: 56.25%] [G loss: 0.723711]\n",
      "414 [D loss: 0.651315, acc.: 56.25%] [G loss: 0.700030]\n",
      "415 [D loss: 0.645552, acc.: 54.69%] [G loss: 0.682647]\n",
      "416 [D loss: 0.644453, acc.: 57.81%] [G loss: 0.693421]\n",
      "417 [D loss: 0.647007, acc.: 54.69%] [G loss: 0.695494]\n",
      "418 [D loss: 0.645536, acc.: 50.00%] [G loss: 0.688610]\n",
      "419 [D loss: 0.675576, acc.: 50.00%] [G loss: 0.725572]\n",
      "420 [D loss: 0.690218, acc.: 48.44%] [G loss: 0.702540]\n",
      "421 [D loss: 0.673593, acc.: 48.44%] [G loss: 0.683366]\n",
      "422 [D loss: 0.663085, acc.: 57.81%] [G loss: 0.679048]\n",
      "423 [D loss: 0.649613, acc.: 56.25%] [G loss: 0.689569]\n",
      "424 [D loss: 0.671769, acc.: 51.56%] [G loss: 0.682848]\n",
      "425 [D loss: 0.654871, acc.: 59.38%] [G loss: 0.673003]\n",
      "426 [D loss: 0.671319, acc.: 54.69%] [G loss: 0.704222]\n",
      "427 [D loss: 0.658128, acc.: 53.12%] [G loss: 0.696771]\n",
      "428 [D loss: 0.661011, acc.: 51.56%] [G loss: 0.684760]\n",
      "429 [D loss: 0.659939, acc.: 57.81%] [G loss: 0.695428]\n",
      "430 [D loss: 0.648323, acc.: 57.81%] [G loss: 0.694603]\n",
      "431 [D loss: 0.644607, acc.: 62.50%] [G loss: 0.702761]\n",
      "432 [D loss: 0.676547, acc.: 56.25%] [G loss: 0.707646]\n",
      "433 [D loss: 0.677319, acc.: 59.38%] [G loss: 0.708252]\n",
      "434 [D loss: 0.634143, acc.: 59.38%] [G loss: 0.714404]\n",
      "435 [D loss: 0.645430, acc.: 64.06%] [G loss: 0.692217]\n",
      "436 [D loss: 0.653778, acc.: 53.12%] [G loss: 0.691005]\n",
      "437 [D loss: 0.654463, acc.: 59.38%] [G loss: 0.702030]\n",
      "438 [D loss: 0.638491, acc.: 62.50%] [G loss: 0.708627]\n",
      "439 [D loss: 0.666042, acc.: 56.25%] [G loss: 0.701306]\n",
      "440 [D loss: 0.657145, acc.: 54.69%] [G loss: 0.688205]\n",
      "441 [D loss: 0.632108, acc.: 62.50%] [G loss: 0.707970]\n",
      "442 [D loss: 0.658191, acc.: 57.81%] [G loss: 0.697609]\n",
      "443 [D loss: 0.661452, acc.: 50.00%] [G loss: 0.705263]\n",
      "444 [D loss: 0.645782, acc.: 65.62%] [G loss: 0.697093]\n",
      "445 [D loss: 0.659449, acc.: 56.25%] [G loss: 0.700093]\n",
      "446 [D loss: 0.642692, acc.: 60.94%] [G loss: 0.713537]\n",
      "447 [D loss: 0.658471, acc.: 64.06%] [G loss: 0.690236]\n",
      "448 [D loss: 0.656513, acc.: 57.81%] [G loss: 0.713199]\n",
      "449 [D loss: 0.669778, acc.: 53.12%] [G loss: 0.737344]\n",
      "450 [D loss: 0.679301, acc.: 46.88%] [G loss: 0.742409]\n",
      "451 [D loss: 0.664635, acc.: 56.25%] [G loss: 0.732900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 [D loss: 0.657287, acc.: 51.56%] [G loss: 0.703429]\n",
      "453 [D loss: 0.657108, acc.: 54.69%] [G loss: 0.726210]\n",
      "454 [D loss: 0.652188, acc.: 60.94%] [G loss: 0.716346]\n",
      "455 [D loss: 0.646644, acc.: 60.94%] [G loss: 0.703084]\n",
      "456 [D loss: 0.649867, acc.: 54.69%] [G loss: 0.722955]\n",
      "457 [D loss: 0.644359, acc.: 53.12%] [G loss: 0.719944]\n",
      "458 [D loss: 0.644393, acc.: 56.25%] [G loss: 0.736314]\n",
      "459 [D loss: 0.647631, acc.: 57.81%] [G loss: 0.730067]\n",
      "460 [D loss: 0.644692, acc.: 56.25%] [G loss: 0.735828]\n",
      "461 [D loss: 0.659098, acc.: 53.12%] [G loss: 0.744106]\n",
      "462 [D loss: 0.638746, acc.: 56.25%] [G loss: 0.763344]\n",
      "463 [D loss: 0.640640, acc.: 62.50%] [G loss: 0.734393]\n",
      "464 [D loss: 0.652120, acc.: 53.12%] [G loss: 0.741261]\n",
      "465 [D loss: 0.637681, acc.: 54.69%] [G loss: 0.731546]\n",
      "466 [D loss: 0.596825, acc.: 60.94%] [G loss: 0.741240]\n",
      "467 [D loss: 0.654071, acc.: 62.50%] [G loss: 0.743159]\n",
      "468 [D loss: 0.632772, acc.: 57.81%] [G loss: 0.749802]\n",
      "469 [D loss: 0.649649, acc.: 56.25%] [G loss: 0.738158]\n",
      "470 [D loss: 0.628688, acc.: 57.81%] [G loss: 0.764702]\n",
      "471 [D loss: 0.632410, acc.: 54.69%] [G loss: 0.759046]\n",
      "472 [D loss: 0.618057, acc.: 60.94%] [G loss: 0.749595]\n",
      "473 [D loss: 0.644810, acc.: 56.25%] [G loss: 0.754812]\n",
      "474 [D loss: 0.624275, acc.: 65.62%] [G loss: 0.770918]\n",
      "475 [D loss: 0.663194, acc.: 50.00%] [G loss: 0.758977]\n",
      "476 [D loss: 0.633240, acc.: 60.94%] [G loss: 0.749856]\n",
      "477 [D loss: 0.630955, acc.: 54.69%] [G loss: 0.719613]\n",
      "478 [D loss: 0.644365, acc.: 59.38%] [G loss: 0.755411]\n",
      "479 [D loss: 0.646938, acc.: 57.81%] [G loss: 0.757033]\n",
      "480 [D loss: 0.623435, acc.: 62.50%] [G loss: 0.756375]\n",
      "481 [D loss: 0.610545, acc.: 70.31%] [G loss: 0.726252]\n",
      "482 [D loss: 0.630155, acc.: 54.69%] [G loss: 0.766703]\n",
      "483 [D loss: 0.636832, acc.: 59.38%] [G loss: 0.728069]\n",
      "484 [D loss: 0.610259, acc.: 64.06%] [G loss: 0.771613]\n",
      "485 [D loss: 0.632761, acc.: 62.50%] [G loss: 0.762152]\n",
      "486 [D loss: 0.634610, acc.: 67.19%] [G loss: 0.792010]\n",
      "487 [D loss: 0.597043, acc.: 68.75%] [G loss: 0.781842]\n",
      "488 [D loss: 0.652672, acc.: 64.06%] [G loss: 0.789073]\n",
      "489 [D loss: 0.643044, acc.: 60.94%] [G loss: 0.765068]\n",
      "490 [D loss: 0.621965, acc.: 68.75%] [G loss: 0.789683]\n",
      "491 [D loss: 0.685088, acc.: 48.44%] [G loss: 0.772178]\n",
      "492 [D loss: 0.615237, acc.: 67.19%] [G loss: 0.774134]\n",
      "493 [D loss: 0.645433, acc.: 60.94%] [G loss: 0.785308]\n",
      "494 [D loss: 0.650849, acc.: 56.25%] [G loss: 0.796275]\n",
      "495 [D loss: 0.652699, acc.: 62.50%] [G loss: 0.798589]\n",
      "496 [D loss: 0.658177, acc.: 51.56%] [G loss: 0.743716]\n",
      "497 [D loss: 0.643801, acc.: 60.94%] [G loss: 0.751496]\n",
      "498 [D loss: 0.629804, acc.: 68.75%] [G loss: 0.755391]\n",
      "499 [D loss: 0.654014, acc.: 57.81%] [G loss: 0.744836]\n",
      "500 [D loss: 0.634775, acc.: 64.06%] [G loss: 0.778903]\n",
      "501 [D loss: 0.646740, acc.: 67.19%] [G loss: 0.750038]\n",
      "502 [D loss: 0.634392, acc.: 62.50%] [G loss: 0.751445]\n",
      "503 [D loss: 0.670681, acc.: 54.69%] [G loss: 0.747671]\n",
      "504 [D loss: 0.672711, acc.: 57.81%] [G loss: 0.773813]\n",
      "505 [D loss: 0.651059, acc.: 60.94%] [G loss: 0.760918]\n",
      "506 [D loss: 0.629340, acc.: 57.81%] [G loss: 0.783387]\n",
      "507 [D loss: 0.658032, acc.: 53.12%] [G loss: 0.724253]\n",
      "508 [D loss: 0.636183, acc.: 60.94%] [G loss: 0.740400]\n",
      "509 [D loss: 0.640924, acc.: 67.19%] [G loss: 0.742827]\n",
      "510 [D loss: 0.618006, acc.: 65.62%] [G loss: 0.730746]\n",
      "511 [D loss: 0.620820, acc.: 64.06%] [G loss: 0.733780]\n",
      "512 [D loss: 0.598979, acc.: 67.19%] [G loss: 0.746002]\n",
      "513 [D loss: 0.655047, acc.: 56.25%] [G loss: 0.737757]\n",
      "514 [D loss: 0.632699, acc.: 67.19%] [G loss: 0.772218]\n",
      "515 [D loss: 0.596309, acc.: 73.44%] [G loss: 0.779976]\n",
      "516 [D loss: 0.620897, acc.: 68.75%] [G loss: 0.772815]\n",
      "517 [D loss: 0.659695, acc.: 57.81%] [G loss: 0.763296]\n",
      "518 [D loss: 0.642338, acc.: 64.06%] [G loss: 0.765615]\n",
      "519 [D loss: 0.628538, acc.: 59.38%] [G loss: 0.781855]\n",
      "520 [D loss: 0.650660, acc.: 62.50%] [G loss: 0.779195]\n",
      "521 [D loss: 0.634132, acc.: 56.25%] [G loss: 0.781589]\n",
      "522 [D loss: 0.634692, acc.: 64.06%] [G loss: 0.778825]\n",
      "523 [D loss: 0.643862, acc.: 67.19%] [G loss: 0.762929]\n",
      "524 [D loss: 0.634646, acc.: 64.06%] [G loss: 0.760070]\n",
      "525 [D loss: 0.658446, acc.: 59.38%] [G loss: 0.724382]\n",
      "526 [D loss: 0.632622, acc.: 59.38%] [G loss: 0.750977]\n",
      "527 [D loss: 0.612823, acc.: 67.19%] [G loss: 0.745968]\n",
      "528 [D loss: 0.646097, acc.: 60.94%] [G loss: 0.755312]\n",
      "529 [D loss: 0.597400, acc.: 67.19%] [G loss: 0.768330]\n",
      "530 [D loss: 0.616872, acc.: 65.62%] [G loss: 0.758365]\n",
      "531 [D loss: 0.616867, acc.: 65.62%] [G loss: 0.782483]\n",
      "532 [D loss: 0.596523, acc.: 71.88%] [G loss: 0.765147]\n",
      "533 [D loss: 0.639617, acc.: 54.69%] [G loss: 0.786484]\n",
      "534 [D loss: 0.614348, acc.: 68.75%] [G loss: 0.760526]\n",
      "535 [D loss: 0.642007, acc.: 56.25%] [G loss: 0.782474]\n",
      "536 [D loss: 0.638219, acc.: 59.38%] [G loss: 0.752118]\n",
      "537 [D loss: 0.628836, acc.: 73.44%] [G loss: 0.756581]\n",
      "538 [D loss: 0.614692, acc.: 67.19%] [G loss: 0.785887]\n",
      "539 [D loss: 0.625505, acc.: 70.31%] [G loss: 0.801222]\n",
      "540 [D loss: 0.611420, acc.: 67.19%] [G loss: 0.782325]\n",
      "541 [D loss: 0.625840, acc.: 68.75%] [G loss: 0.769301]\n",
      "542 [D loss: 0.604543, acc.: 70.31%] [G loss: 0.780531]\n",
      "543 [D loss: 0.628142, acc.: 62.50%] [G loss: 0.798864]\n",
      "544 [D loss: 0.626759, acc.: 70.31%] [G loss: 0.765996]\n",
      "545 [D loss: 0.624331, acc.: 60.94%] [G loss: 0.757620]\n",
      "546 [D loss: 0.682992, acc.: 45.31%] [G loss: 0.753353]\n",
      "547 [D loss: 0.663206, acc.: 54.69%] [G loss: 0.796355]\n",
      "548 [D loss: 0.637047, acc.: 62.50%] [G loss: 0.782816]\n",
      "549 [D loss: 0.630535, acc.: 67.19%] [G loss: 0.803256]\n",
      "550 [D loss: 0.607363, acc.: 75.00%] [G loss: 0.783098]\n",
      "551 [D loss: 0.630021, acc.: 67.19%] [G loss: 0.780043]\n",
      "552 [D loss: 0.635784, acc.: 64.06%] [G loss: 0.745899]\n",
      "553 [D loss: 0.651538, acc.: 64.06%] [G loss: 0.741889]\n",
      "554 [D loss: 0.622721, acc.: 65.62%] [G loss: 0.732042]\n",
      "555 [D loss: 0.647538, acc.: 57.81%] [G loss: 0.753684]\n",
      "556 [D loss: 0.637280, acc.: 59.38%] [G loss: 0.749546]\n",
      "557 [D loss: 0.615113, acc.: 67.19%] [G loss: 0.780895]\n",
      "558 [D loss: 0.616551, acc.: 65.62%] [G loss: 0.743031]\n",
      "559 [D loss: 0.656896, acc.: 54.69%] [G loss: 0.711824]\n",
      "560 [D loss: 0.665251, acc.: 56.25%] [G loss: 0.755050]\n",
      "561 [D loss: 0.619822, acc.: 62.50%] [G loss: 0.747340]\n",
      "562 [D loss: 0.653923, acc.: 57.81%] [G loss: 0.776532]\n",
      "563 [D loss: 0.658641, acc.: 54.69%] [G loss: 0.778651]\n",
      "564 [D loss: 0.653309, acc.: 57.81%] [G loss: 0.793386]\n",
      "565 [D loss: 0.668636, acc.: 57.81%] [G loss: 0.763846]\n",
      "566 [D loss: 0.641279, acc.: 67.19%] [G loss: 0.766248]\n",
      "567 [D loss: 0.635961, acc.: 64.06%] [G loss: 0.771864]\n",
      "568 [D loss: 0.636889, acc.: 62.50%] [G loss: 0.786640]\n",
      "569 [D loss: 0.638393, acc.: 62.50%] [G loss: 0.810559]\n",
      "570 [D loss: 0.649192, acc.: 59.38%] [G loss: 0.754141]\n",
      "571 [D loss: 0.634390, acc.: 59.38%] [G loss: 0.778014]\n",
      "572 [D loss: 0.625837, acc.: 62.50%] [G loss: 0.812251]\n",
      "573 [D loss: 0.642838, acc.: 68.75%] [G loss: 0.784375]\n",
      "574 [D loss: 0.640111, acc.: 62.50%] [G loss: 0.777700]\n",
      "575 [D loss: 0.612066, acc.: 70.31%] [G loss: 0.760564]\n",
      "576 [D loss: 0.634535, acc.: 60.94%] [G loss: 0.759099]\n",
      "577 [D loss: 0.625671, acc.: 62.50%] [G loss: 0.776584]\n",
      "578 [D loss: 0.630309, acc.: 65.62%] [G loss: 0.761660]\n",
      "579 [D loss: 0.649840, acc.: 64.06%] [G loss: 0.744219]\n",
      "580 [D loss: 0.659551, acc.: 59.38%] [G loss: 0.751944]\n",
      "581 [D loss: 0.663751, acc.: 57.81%] [G loss: 0.741065]\n",
      "582 [D loss: 0.648594, acc.: 57.81%] [G loss: 0.771344]\n",
      "583 [D loss: 0.625109, acc.: 60.94%] [G loss: 0.741989]\n",
      "584 [D loss: 0.625599, acc.: 68.75%] [G loss: 0.779743]\n",
      "585 [D loss: 0.642501, acc.: 64.06%] [G loss: 0.740770]\n",
      "586 [D loss: 0.631095, acc.: 64.06%] [G loss: 0.751571]\n",
      "587 [D loss: 0.653636, acc.: 51.56%] [G loss: 0.792136]\n",
      "588 [D loss: 0.678065, acc.: 51.56%] [G loss: 0.796283]\n",
      "589 [D loss: 0.677843, acc.: 50.00%] [G loss: 0.751574]\n",
      "590 [D loss: 0.669320, acc.: 54.69%] [G loss: 0.765238]\n",
      "591 [D loss: 0.629169, acc.: 67.19%] [G loss: 0.801091]\n",
      "592 [D loss: 0.661870, acc.: 56.25%] [G loss: 0.735367]\n",
      "593 [D loss: 0.671267, acc.: 42.19%] [G loss: 0.732623]\n",
      "594 [D loss: 0.636912, acc.: 65.62%] [G loss: 0.735760]\n",
      "595 [D loss: 0.658968, acc.: 62.50%] [G loss: 0.774708]\n",
      "596 [D loss: 0.685740, acc.: 48.44%] [G loss: 0.742313]\n",
      "597 [D loss: 0.664670, acc.: 53.12%] [G loss: 0.756983]\n",
      "598 [D loss: 0.657842, acc.: 57.81%] [G loss: 0.767143]\n",
      "599 [D loss: 0.665745, acc.: 56.25%] [G loss: 0.757886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 [D loss: 0.661382, acc.: 60.94%] [G loss: 0.751451]\n",
      "601 [D loss: 0.674536, acc.: 57.81%] [G loss: 0.732647]\n",
      "602 [D loss: 0.659979, acc.: 57.81%] [G loss: 0.753762]\n",
      "603 [D loss: 0.663564, acc.: 57.81%] [G loss: 0.772675]\n",
      "604 [D loss: 0.662064, acc.: 56.25%] [G loss: 0.746561]\n",
      "605 [D loss: 0.636806, acc.: 57.81%] [G loss: 0.733035]\n",
      "606 [D loss: 0.650859, acc.: 57.81%] [G loss: 0.729533]\n",
      "607 [D loss: 0.665511, acc.: 57.81%] [G loss: 0.739542]\n",
      "608 [D loss: 0.646044, acc.: 59.38%] [G loss: 0.745544]\n",
      "609 [D loss: 0.640818, acc.: 60.94%] [G loss: 0.728528]\n",
      "610 [D loss: 0.647840, acc.: 64.06%] [G loss: 0.731964]\n",
      "611 [D loss: 0.674078, acc.: 57.81%] [G loss: 0.767158]\n",
      "612 [D loss: 0.615757, acc.: 70.31%] [G loss: 0.750253]\n",
      "613 [D loss: 0.649843, acc.: 59.38%] [G loss: 0.789827]\n",
      "614 [D loss: 0.667085, acc.: 56.25%] [G loss: 0.781238]\n",
      "615 [D loss: 0.629004, acc.: 60.94%] [G loss: 0.773056]\n",
      "616 [D loss: 0.665342, acc.: 62.50%] [G loss: 0.728473]\n",
      "617 [D loss: 0.652181, acc.: 65.62%] [G loss: 0.755541]\n",
      "618 [D loss: 0.692505, acc.: 57.81%] [G loss: 0.800907]\n",
      "619 [D loss: 0.667744, acc.: 64.06%] [G loss: 0.754721]\n",
      "620 [D loss: 0.663733, acc.: 60.94%] [G loss: 0.770559]\n",
      "621 [D loss: 0.631433, acc.: 64.06%] [G loss: 0.747256]\n",
      "622 [D loss: 0.667016, acc.: 50.00%] [G loss: 0.740836]\n",
      "623 [D loss: 0.670892, acc.: 53.12%] [G loss: 0.741938]\n",
      "624 [D loss: 0.637032, acc.: 64.06%] [G loss: 0.768019]\n",
      "625 [D loss: 0.655234, acc.: 57.81%] [G loss: 0.758142]\n",
      "626 [D loss: 0.633472, acc.: 65.62%] [G loss: 0.758130]\n",
      "627 [D loss: 0.654747, acc.: 57.81%] [G loss: 0.795407]\n",
      "628 [D loss: 0.611639, acc.: 73.44%] [G loss: 0.804767]\n",
      "629 [D loss: 0.649335, acc.: 62.50%] [G loss: 0.766331]\n",
      "630 [D loss: 0.647027, acc.: 59.38%] [G loss: 0.762178]\n",
      "631 [D loss: 0.661853, acc.: 59.38%] [G loss: 0.747056]\n",
      "632 [D loss: 0.635654, acc.: 62.50%] [G loss: 0.748249]\n",
      "633 [D loss: 0.614763, acc.: 65.62%] [G loss: 0.753521]\n",
      "634 [D loss: 0.619787, acc.: 70.31%] [G loss: 0.775920]\n",
      "635 [D loss: 0.659876, acc.: 59.38%] [G loss: 0.786555]\n",
      "636 [D loss: 0.623074, acc.: 65.62%] [G loss: 0.800022]\n",
      "637 [D loss: 0.636284, acc.: 67.19%] [G loss: 0.764187]\n",
      "638 [D loss: 0.652091, acc.: 62.50%] [G loss: 0.778502]\n",
      "639 [D loss: 0.650937, acc.: 67.19%] [G loss: 0.739306]\n",
      "640 [D loss: 0.612783, acc.: 70.31%] [G loss: 0.788554]\n",
      "641 [D loss: 0.624041, acc.: 65.62%] [G loss: 0.755839]\n",
      "642 [D loss: 0.650396, acc.: 56.25%] [G loss: 0.778511]\n",
      "643 [D loss: 0.625499, acc.: 73.44%] [G loss: 0.736960]\n",
      "644 [D loss: 0.637319, acc.: 60.94%] [G loss: 0.765698]\n",
      "645 [D loss: 0.623157, acc.: 65.62%] [G loss: 0.751362]\n",
      "646 [D loss: 0.642576, acc.: 64.06%] [G loss: 0.743739]\n",
      "647 [D loss: 0.667144, acc.: 54.69%] [G loss: 0.759779]\n",
      "648 [D loss: 0.621340, acc.: 65.62%] [G loss: 0.774574]\n",
      "649 [D loss: 0.634731, acc.: 67.19%] [G loss: 0.772904]\n",
      "650 [D loss: 0.648419, acc.: 57.81%] [G loss: 0.784400]\n",
      "651 [D loss: 0.663375, acc.: 51.56%] [G loss: 0.746029]\n",
      "652 [D loss: 0.635020, acc.: 60.94%] [G loss: 0.743275]\n",
      "653 [D loss: 0.652270, acc.: 65.62%] [G loss: 0.735739]\n",
      "654 [D loss: 0.635378, acc.: 62.50%] [G loss: 0.739303]\n",
      "655 [D loss: 0.620190, acc.: 68.75%] [G loss: 0.740825]\n",
      "656 [D loss: 0.662301, acc.: 60.94%] [G loss: 0.722445]\n",
      "657 [D loss: 0.656265, acc.: 53.12%] [G loss: 0.761292]\n",
      "658 [D loss: 0.620497, acc.: 68.75%] [G loss: 0.732269]\n",
      "659 [D loss: 0.650081, acc.: 65.62%] [G loss: 0.797340]\n",
      "660 [D loss: 0.617489, acc.: 62.50%] [G loss: 0.770872]\n",
      "661 [D loss: 0.613230, acc.: 73.44%] [G loss: 0.750285]\n",
      "662 [D loss: 0.656180, acc.: 59.38%] [G loss: 0.753277]\n",
      "663 [D loss: 0.640652, acc.: 64.06%] [G loss: 0.737860]\n",
      "664 [D loss: 0.606977, acc.: 59.38%] [G loss: 0.767268]\n",
      "665 [D loss: 0.632730, acc.: 64.06%] [G loss: 0.773848]\n",
      "666 [D loss: 0.640112, acc.: 64.06%] [G loss: 0.778377]\n",
      "667 [D loss: 0.652630, acc.: 59.38%] [G loss: 0.758730]\n",
      "668 [D loss: 0.629812, acc.: 56.25%] [G loss: 0.784899]\n",
      "669 [D loss: 0.621938, acc.: 62.50%] [G loss: 0.778540]\n",
      "670 [D loss: 0.609405, acc.: 70.31%] [G loss: 0.806159]\n",
      "671 [D loss: 0.652460, acc.: 53.12%] [G loss: 0.782095]\n",
      "672 [D loss: 0.613421, acc.: 70.31%] [G loss: 0.771580]\n",
      "673 [D loss: 0.585620, acc.: 71.88%] [G loss: 0.772651]\n",
      "674 [D loss: 0.626982, acc.: 60.94%] [G loss: 0.771537]\n",
      "675 [D loss: 0.617036, acc.: 62.50%] [G loss: 0.794875]\n",
      "676 [D loss: 0.674269, acc.: 57.81%] [G loss: 0.779720]\n",
      "677 [D loss: 0.650158, acc.: 65.62%] [G loss: 0.786100]\n",
      "678 [D loss: 0.634215, acc.: 67.19%] [G loss: 0.742207]\n",
      "679 [D loss: 0.632294, acc.: 64.06%] [G loss: 0.783744]\n",
      "680 [D loss: 0.677347, acc.: 56.25%] [G loss: 0.774153]\n",
      "681 [D loss: 0.633886, acc.: 64.06%] [G loss: 0.765094]\n",
      "682 [D loss: 0.656677, acc.: 59.38%] [G loss: 0.764706]\n",
      "683 [D loss: 0.652656, acc.: 53.12%] [G loss: 0.788587]\n",
      "684 [D loss: 0.679260, acc.: 60.94%] [G loss: 0.754748]\n",
      "685 [D loss: 0.608848, acc.: 67.19%] [G loss: 0.790265]\n",
      "686 [D loss: 0.654272, acc.: 56.25%] [G loss: 0.799766]\n",
      "687 [D loss: 0.624480, acc.: 73.44%] [G loss: 0.788508]\n",
      "688 [D loss: 0.661368, acc.: 54.69%] [G loss: 0.733908]\n",
      "689 [D loss: 0.641729, acc.: 70.31%] [G loss: 0.766213]\n",
      "690 [D loss: 0.646442, acc.: 57.81%] [G loss: 0.749907]\n",
      "691 [D loss: 0.637157, acc.: 68.75%] [G loss: 0.748672]\n",
      "692 [D loss: 0.629285, acc.: 75.00%] [G loss: 0.740306]\n",
      "693 [D loss: 0.618164, acc.: 71.88%] [G loss: 0.766129]\n",
      "694 [D loss: 0.569162, acc.: 78.12%] [G loss: 0.755268]\n",
      "695 [D loss: 0.633874, acc.: 67.19%] [G loss: 0.785239]\n",
      "696 [D loss: 0.635261, acc.: 57.81%] [G loss: 0.745981]\n",
      "697 [D loss: 0.616308, acc.: 64.06%] [G loss: 0.778783]\n",
      "698 [D loss: 0.652670, acc.: 64.06%] [G loss: 0.772089]\n",
      "699 [D loss: 0.668368, acc.: 53.12%] [G loss: 0.755490]\n",
      "700 [D loss: 0.650061, acc.: 62.50%] [G loss: 0.770272]\n",
      "701 [D loss: 0.613795, acc.: 68.75%] [G loss: 0.806149]\n",
      "702 [D loss: 0.638487, acc.: 68.75%] [G loss: 0.791415]\n",
      "703 [D loss: 0.638436, acc.: 68.75%] [G loss: 0.818402]\n",
      "704 [D loss: 0.637146, acc.: 60.94%] [G loss: 0.789157]\n",
      "705 [D loss: 0.649396, acc.: 54.69%] [G loss: 0.753784]\n",
      "706 [D loss: 0.641934, acc.: 59.38%] [G loss: 0.774552]\n",
      "707 [D loss: 0.629072, acc.: 65.62%] [G loss: 0.772773]\n",
      "708 [D loss: 0.639487, acc.: 73.44%] [G loss: 0.761632]\n",
      "709 [D loss: 0.646575, acc.: 62.50%] [G loss: 0.770348]\n",
      "710 [D loss: 0.624525, acc.: 70.31%] [G loss: 0.787501]\n",
      "711 [D loss: 0.664907, acc.: 56.25%] [G loss: 0.775949]\n",
      "712 [D loss: 0.638873, acc.: 64.06%] [G loss: 0.775105]\n",
      "713 [D loss: 0.648016, acc.: 62.50%] [G loss: 0.747142]\n",
      "714 [D loss: 0.662709, acc.: 60.94%] [G loss: 0.784221]\n",
      "715 [D loss: 0.678405, acc.: 56.25%] [G loss: 0.787801]\n",
      "716 [D loss: 0.654515, acc.: 60.94%] [G loss: 0.790484]\n",
      "717 [D loss: 0.649009, acc.: 65.62%] [G loss: 0.782688]\n",
      "718 [D loss: 0.671366, acc.: 57.81%] [G loss: 0.777508]\n",
      "719 [D loss: 0.634966, acc.: 67.19%] [G loss: 0.804477]\n",
      "720 [D loss: 0.659447, acc.: 60.94%] [G loss: 0.773106]\n",
      "721 [D loss: 0.641952, acc.: 60.94%] [G loss: 0.798375]\n",
      "722 [D loss: 0.649305, acc.: 59.38%] [G loss: 0.786090]\n",
      "723 [D loss: 0.621205, acc.: 67.19%] [G loss: 0.792206]\n",
      "724 [D loss: 0.621698, acc.: 73.44%] [G loss: 0.797750]\n",
      "725 [D loss: 0.632560, acc.: 64.06%] [G loss: 0.745360]\n",
      "726 [D loss: 0.609142, acc.: 67.19%] [G loss: 0.788541]\n",
      "727 [D loss: 0.630733, acc.: 68.75%] [G loss: 0.774528]\n",
      "728 [D loss: 0.648370, acc.: 65.62%] [G loss: 0.799771]\n",
      "729 [D loss: 0.692833, acc.: 42.19%] [G loss: 0.748393]\n",
      "730 [D loss: 0.652311, acc.: 57.81%] [G loss: 0.763808]\n",
      "731 [D loss: 0.625725, acc.: 68.75%] [G loss: 0.774202]\n",
      "732 [D loss: 0.633211, acc.: 65.62%] [G loss: 0.760056]\n",
      "733 [D loss: 0.622800, acc.: 70.31%] [G loss: 0.767139]\n",
      "734 [D loss: 0.609295, acc.: 78.12%] [G loss: 0.800319]\n",
      "735 [D loss: 0.588426, acc.: 73.44%] [G loss: 0.809286]\n",
      "736 [D loss: 0.627765, acc.: 59.38%] [G loss: 0.766193]\n",
      "737 [D loss: 0.642920, acc.: 64.06%] [G loss: 0.773472]\n",
      "738 [D loss: 0.624895, acc.: 70.31%] [G loss: 0.772341]\n",
      "739 [D loss: 0.625355, acc.: 71.88%] [G loss: 0.775950]\n",
      "740 [D loss: 0.622306, acc.: 68.75%] [G loss: 0.785066]\n",
      "741 [D loss: 0.612150, acc.: 73.44%] [G loss: 0.769224]\n",
      "742 [D loss: 0.609991, acc.: 75.00%] [G loss: 0.781440]\n",
      "743 [D loss: 0.629762, acc.: 67.19%] [G loss: 0.767040]\n",
      "744 [D loss: 0.618078, acc.: 65.62%] [G loss: 0.803766]\n",
      "745 [D loss: 0.636668, acc.: 68.75%] [G loss: 0.798812]\n",
      "746 [D loss: 0.649922, acc.: 67.19%] [G loss: 0.772147]\n",
      "747 [D loss: 0.609001, acc.: 65.62%] [G loss: 0.780136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748 [D loss: 0.612823, acc.: 71.88%] [G loss: 0.754952]\n",
      "749 [D loss: 0.631224, acc.: 70.31%] [G loss: 0.729479]\n",
      "750 [D loss: 0.615870, acc.: 68.75%] [G loss: 0.766102]\n",
      "751 [D loss: 0.629457, acc.: 70.31%] [G loss: 0.769915]\n",
      "752 [D loss: 0.633869, acc.: 64.06%] [G loss: 0.781952]\n",
      "753 [D loss: 0.632805, acc.: 65.62%] [G loss: 0.787800]\n",
      "754 [D loss: 0.590908, acc.: 70.31%] [G loss: 0.812571]\n",
      "755 [D loss: 0.618185, acc.: 67.19%] [G loss: 0.801587]\n",
      "756 [D loss: 0.632501, acc.: 64.06%] [G loss: 0.814900]\n",
      "757 [D loss: 0.634628, acc.: 57.81%] [G loss: 0.810390]\n",
      "758 [D loss: 0.634443, acc.: 62.50%] [G loss: 0.814144]\n",
      "759 [D loss: 0.644933, acc.: 64.06%] [G loss: 0.776303]\n",
      "760 [D loss: 0.668280, acc.: 59.38%] [G loss: 0.791681]\n",
      "761 [D loss: 0.649551, acc.: 57.81%] [G loss: 0.796990]\n",
      "762 [D loss: 0.609113, acc.: 75.00%] [G loss: 0.787053]\n",
      "763 [D loss: 0.636249, acc.: 64.06%] [G loss: 0.807029]\n",
      "764 [D loss: 0.636922, acc.: 64.06%] [G loss: 0.771037]\n",
      "765 [D loss: 0.672829, acc.: 56.25%] [G loss: 0.785512]\n",
      "766 [D loss: 0.653933, acc.: 60.94%] [G loss: 0.782385]\n",
      "767 [D loss: 0.666451, acc.: 56.25%] [G loss: 0.762896]\n",
      "768 [D loss: 0.680430, acc.: 54.69%] [G loss: 0.766070]\n",
      "769 [D loss: 0.625452, acc.: 68.75%] [G loss: 0.818687]\n",
      "770 [D loss: 0.669025, acc.: 59.38%] [G loss: 0.821393]\n",
      "771 [D loss: 0.613157, acc.: 75.00%] [G loss: 0.803752]\n",
      "772 [D loss: 0.677007, acc.: 56.25%] [G loss: 0.857538]\n",
      "773 [D loss: 0.672788, acc.: 56.25%] [G loss: 0.790498]\n",
      "774 [D loss: 0.622142, acc.: 68.75%] [G loss: 0.779709]\n",
      "775 [D loss: 0.638536, acc.: 68.75%] [G loss: 0.804919]\n",
      "776 [D loss: 0.693746, acc.: 59.38%] [G loss: 0.770922]\n",
      "777 [D loss: 0.615933, acc.: 71.88%] [G loss: 0.785689]\n",
      "778 [D loss: 0.663539, acc.: 59.38%] [G loss: 0.788728]\n",
      "779 [D loss: 0.652704, acc.: 53.12%] [G loss: 0.758443]\n",
      "780 [D loss: 0.660708, acc.: 56.25%] [G loss: 0.787982]\n",
      "781 [D loss: 0.625609, acc.: 65.62%] [G loss: 0.791660]\n",
      "782 [D loss: 0.647467, acc.: 62.50%] [G loss: 0.820173]\n",
      "783 [D loss: 0.632489, acc.: 64.06%] [G loss: 0.818376]\n",
      "784 [D loss: 0.633087, acc.: 65.62%] [G loss: 0.840149]\n",
      "785 [D loss: 0.639613, acc.: 67.19%] [G loss: 0.804797]\n",
      "786 [D loss: 0.650057, acc.: 56.25%] [G loss: 0.813484]\n",
      "787 [D loss: 0.656858, acc.: 57.81%] [G loss: 0.797268]\n",
      "788 [D loss: 0.658814, acc.: 64.06%] [G loss: 0.804716]\n",
      "789 [D loss: 0.637548, acc.: 65.62%] [G loss: 0.771786]\n",
      "790 [D loss: 0.640489, acc.: 70.31%] [G loss: 0.747632]\n",
      "791 [D loss: 0.648016, acc.: 73.44%] [G loss: 0.750055]\n",
      "792 [D loss: 0.650749, acc.: 56.25%] [G loss: 0.771969]\n",
      "793 [D loss: 0.674034, acc.: 54.69%] [G loss: 0.778780]\n",
      "794 [D loss: 0.612462, acc.: 68.75%] [G loss: 0.805402]\n",
      "795 [D loss: 0.648316, acc.: 67.19%] [G loss: 0.785617]\n",
      "796 [D loss: 0.657502, acc.: 65.62%] [G loss: 0.790102]\n",
      "797 [D loss: 0.617367, acc.: 65.62%] [G loss: 0.789116]\n",
      "798 [D loss: 0.606735, acc.: 79.69%] [G loss: 0.772249]\n",
      "799 [D loss: 0.643631, acc.: 60.94%] [G loss: 0.776101]\n",
      "800 [D loss: 0.666629, acc.: 56.25%] [G loss: 0.747663]\n",
      "801 [D loss: 0.626096, acc.: 71.88%] [G loss: 0.790228]\n",
      "802 [D loss: 0.579427, acc.: 78.12%] [G loss: 0.778121]\n",
      "803 [D loss: 0.636582, acc.: 65.62%] [G loss: 0.817065]\n",
      "804 [D loss: 0.625621, acc.: 68.75%] [G loss: 0.793262]\n",
      "805 [D loss: 0.642211, acc.: 57.81%] [G loss: 0.795391]\n",
      "806 [D loss: 0.615845, acc.: 71.88%] [G loss: 0.798549]\n",
      "807 [D loss: 0.660254, acc.: 59.38%] [G loss: 0.827666]\n",
      "808 [D loss: 0.657883, acc.: 60.94%] [G loss: 0.817025]\n",
      "809 [D loss: 0.642124, acc.: 67.19%] [G loss: 0.818310]\n",
      "810 [D loss: 0.624564, acc.: 78.12%] [G loss: 0.830962]\n",
      "811 [D loss: 0.624430, acc.: 65.62%] [G loss: 0.818387]\n",
      "812 [D loss: 0.635621, acc.: 67.19%] [G loss: 0.806762]\n",
      "813 [D loss: 0.626896, acc.: 65.62%] [G loss: 0.829460]\n",
      "814 [D loss: 0.616801, acc.: 68.75%] [G loss: 0.804355]\n",
      "815 [D loss: 0.637838, acc.: 68.75%] [G loss: 0.848580]\n",
      "816 [D loss: 0.661478, acc.: 53.12%] [G loss: 0.853642]\n",
      "817 [D loss: 0.659347, acc.: 59.38%] [G loss: 0.860419]\n",
      "818 [D loss: 0.615141, acc.: 73.44%] [G loss: 0.813027]\n",
      "819 [D loss: 0.658394, acc.: 67.19%] [G loss: 0.849015]\n",
      "820 [D loss: 0.647415, acc.: 71.88%] [G loss: 0.778421]\n",
      "821 [D loss: 0.648982, acc.: 62.50%] [G loss: 0.765740]\n",
      "822 [D loss: 0.656039, acc.: 64.06%] [G loss: 0.787976]\n",
      "823 [D loss: 0.640847, acc.: 62.50%] [G loss: 0.801255]\n",
      "824 [D loss: 0.636741, acc.: 73.44%] [G loss: 0.770006]\n",
      "825 [D loss: 0.623606, acc.: 67.19%] [G loss: 0.759596]\n",
      "826 [D loss: 0.626794, acc.: 67.19%] [G loss: 0.805081]\n",
      "827 [D loss: 0.614758, acc.: 65.62%] [G loss: 0.782377]\n",
      "828 [D loss: 0.642421, acc.: 60.94%] [G loss: 0.762765]\n",
      "829 [D loss: 0.641040, acc.: 68.75%] [G loss: 0.787620]\n",
      "830 [D loss: 0.634654, acc.: 62.50%] [G loss: 0.800687]\n",
      "831 [D loss: 0.635107, acc.: 65.62%] [G loss: 0.811157]\n",
      "832 [D loss: 0.623965, acc.: 70.31%] [G loss: 0.800241]\n",
      "833 [D loss: 0.658789, acc.: 59.38%] [G loss: 0.813998]\n",
      "834 [D loss: 0.618418, acc.: 70.31%] [G loss: 0.805396]\n",
      "835 [D loss: 0.652194, acc.: 60.94%] [G loss: 0.851371]\n",
      "836 [D loss: 0.659984, acc.: 56.25%] [G loss: 0.772014]\n",
      "837 [D loss: 0.629742, acc.: 67.19%] [G loss: 0.773813]\n",
      "838 [D loss: 0.633155, acc.: 70.31%] [G loss: 0.792348]\n",
      "839 [D loss: 0.642640, acc.: 56.25%] [G loss: 0.795112]\n",
      "840 [D loss: 0.658703, acc.: 67.19%] [G loss: 0.813254]\n",
      "841 [D loss: 0.611985, acc.: 75.00%] [G loss: 0.811600]\n",
      "842 [D loss: 0.633223, acc.: 73.44%] [G loss: 0.842149]\n",
      "843 [D loss: 0.670583, acc.: 56.25%] [G loss: 0.816686]\n",
      "844 [D loss: 0.579437, acc.: 84.38%] [G loss: 0.826889]\n",
      "845 [D loss: 0.603326, acc.: 76.56%] [G loss: 0.813331]\n",
      "846 [D loss: 0.626424, acc.: 68.75%] [G loss: 0.804031]\n",
      "847 [D loss: 0.612977, acc.: 75.00%] [G loss: 0.782225]\n",
      "848 [D loss: 0.613107, acc.: 65.62%] [G loss: 0.838890]\n",
      "849 [D loss: 0.640105, acc.: 67.19%] [G loss: 0.814121]\n",
      "850 [D loss: 0.575362, acc.: 79.69%] [G loss: 0.831456]\n",
      "851 [D loss: 0.639183, acc.: 67.19%] [G loss: 0.800747]\n",
      "852 [D loss: 0.623824, acc.: 71.88%] [G loss: 0.830407]\n",
      "853 [D loss: 0.624007, acc.: 67.19%] [G loss: 0.817836]\n",
      "854 [D loss: 0.636256, acc.: 62.50%] [G loss: 0.745065]\n",
      "855 [D loss: 0.619964, acc.: 73.44%] [G loss: 0.770571]\n",
      "856 [D loss: 0.576768, acc.: 78.12%] [G loss: 0.815254]\n",
      "857 [D loss: 0.620070, acc.: 68.75%] [G loss: 0.796468]\n",
      "858 [D loss: 0.623872, acc.: 65.62%] [G loss: 0.820546]\n",
      "859 [D loss: 0.637769, acc.: 62.50%] [G loss: 0.788174]\n",
      "860 [D loss: 0.627896, acc.: 59.38%] [G loss: 0.796127]\n",
      "861 [D loss: 0.618173, acc.: 65.62%] [G loss: 0.808492]\n",
      "862 [D loss: 0.607640, acc.: 68.75%] [G loss: 0.829168]\n",
      "863 [D loss: 0.643132, acc.: 64.06%] [G loss: 0.796775]\n",
      "864 [D loss: 0.637405, acc.: 64.06%] [G loss: 0.781370]\n",
      "865 [D loss: 0.601968, acc.: 62.50%] [G loss: 0.815925]\n",
      "866 [D loss: 0.645084, acc.: 57.81%] [G loss: 0.774187]\n",
      "867 [D loss: 0.613961, acc.: 75.00%] [G loss: 0.823485]\n",
      "868 [D loss: 0.621826, acc.: 67.19%] [G loss: 0.840299]\n",
      "869 [D loss: 0.621347, acc.: 62.50%] [G loss: 0.857084]\n",
      "870 [D loss: 0.581223, acc.: 71.88%] [G loss: 0.869197]\n",
      "871 [D loss: 0.651225, acc.: 67.19%] [G loss: 0.816951]\n",
      "872 [D loss: 0.588172, acc.: 75.00%] [G loss: 0.825997]\n",
      "873 [D loss: 0.640507, acc.: 60.94%] [G loss: 0.851453]\n",
      "874 [D loss: 0.592239, acc.: 68.75%] [G loss: 0.826350]\n",
      "875 [D loss: 0.664771, acc.: 64.06%] [G loss: 0.795010]\n",
      "876 [D loss: 0.584468, acc.: 75.00%] [G loss: 0.792369]\n",
      "877 [D loss: 0.624286, acc.: 68.75%] [G loss: 0.794681]\n",
      "878 [D loss: 0.570137, acc.: 81.25%] [G loss: 0.771860]\n",
      "879 [D loss: 0.638299, acc.: 67.19%] [G loss: 0.771388]\n",
      "880 [D loss: 0.641203, acc.: 57.81%] [G loss: 0.823993]\n",
      "881 [D loss: 0.609082, acc.: 70.31%] [G loss: 0.844942]\n",
      "882 [D loss: 0.622310, acc.: 71.88%] [G loss: 0.795451]\n",
      "883 [D loss: 0.615501, acc.: 71.88%] [G loss: 0.881311]\n",
      "884 [D loss: 0.618407, acc.: 73.44%] [G loss: 0.861207]\n",
      "885 [D loss: 0.633281, acc.: 73.44%] [G loss: 0.798305]\n",
      "886 [D loss: 0.627461, acc.: 64.06%] [G loss: 0.806068]\n",
      "887 [D loss: 0.576028, acc.: 79.69%] [G loss: 0.815216]\n",
      "888 [D loss: 0.612989, acc.: 68.75%] [G loss: 0.824561]\n",
      "889 [D loss: 0.610052, acc.: 71.88%] [G loss: 0.832382]\n",
      "890 [D loss: 0.625377, acc.: 71.88%] [G loss: 0.839548]\n",
      "891 [D loss: 0.604083, acc.: 73.44%] [G loss: 0.859455]\n",
      "892 [D loss: 0.601806, acc.: 70.31%] [G loss: 0.898559]\n",
      "893 [D loss: 0.621478, acc.: 64.06%] [G loss: 0.807105]\n",
      "894 [D loss: 0.603120, acc.: 68.75%] [G loss: 0.845692]\n",
      "895 [D loss: 0.607098, acc.: 64.06%] [G loss: 0.848677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896 [D loss: 0.575733, acc.: 81.25%] [G loss: 0.859426]\n",
      "897 [D loss: 0.589715, acc.: 68.75%] [G loss: 0.856717]\n",
      "898 [D loss: 0.601180, acc.: 73.44%] [G loss: 0.842577]\n",
      "899 [D loss: 0.632163, acc.: 71.88%] [G loss: 0.831454]\n",
      "900 [D loss: 0.614273, acc.: 65.62%] [G loss: 0.810726]\n",
      "901 [D loss: 0.629592, acc.: 60.94%] [G loss: 0.841410]\n",
      "902 [D loss: 0.618275, acc.: 70.31%] [G loss: 0.852952]\n",
      "903 [D loss: 0.607843, acc.: 73.44%] [G loss: 0.819092]\n",
      "904 [D loss: 0.621070, acc.: 62.50%] [G loss: 0.829983]\n",
      "905 [D loss: 0.602225, acc.: 71.88%] [G loss: 0.812250]\n",
      "906 [D loss: 0.585478, acc.: 70.31%] [G loss: 0.850966]\n",
      "907 [D loss: 0.643834, acc.: 62.50%] [G loss: 0.817738]\n",
      "908 [D loss: 0.605602, acc.: 70.31%] [G loss: 0.830966]\n",
      "909 [D loss: 0.597327, acc.: 70.31%] [G loss: 0.851877]\n",
      "910 [D loss: 0.607026, acc.: 71.88%] [G loss: 0.857152]\n",
      "911 [D loss: 0.602240, acc.: 75.00%] [G loss: 0.838304]\n",
      "912 [D loss: 0.603243, acc.: 73.44%] [G loss: 0.828604]\n",
      "913 [D loss: 0.560900, acc.: 85.94%] [G loss: 0.807883]\n",
      "914 [D loss: 0.621068, acc.: 60.94%] [G loss: 0.789916]\n",
      "915 [D loss: 0.641263, acc.: 62.50%] [G loss: 0.805809]\n",
      "916 [D loss: 0.660529, acc.: 64.06%] [G loss: 0.771815]\n",
      "917 [D loss: 0.576709, acc.: 75.00%] [G loss: 0.805891]\n",
      "918 [D loss: 0.621850, acc.: 62.50%] [G loss: 0.817153]\n",
      "919 [D loss: 0.602105, acc.: 73.44%] [G loss: 0.862734]\n",
      "920 [D loss: 0.596792, acc.: 71.88%] [G loss: 0.887364]\n",
      "921 [D loss: 0.622713, acc.: 71.88%] [G loss: 0.842806]\n",
      "922 [D loss: 0.623288, acc.: 70.31%] [G loss: 0.811557]\n",
      "923 [D loss: 0.624543, acc.: 64.06%] [G loss: 0.822429]\n",
      "924 [D loss: 0.592301, acc.: 79.69%] [G loss: 0.830456]\n",
      "925 [D loss: 0.594323, acc.: 67.19%] [G loss: 0.824563]\n",
      "926 [D loss: 0.638022, acc.: 68.75%] [G loss: 0.845185]\n",
      "927 [D loss: 0.618239, acc.: 65.62%] [G loss: 0.846068]\n",
      "928 [D loss: 0.634101, acc.: 67.19%] [G loss: 0.815207]\n",
      "929 [D loss: 0.555569, acc.: 76.56%] [G loss: 0.845837]\n",
      "930 [D loss: 0.612461, acc.: 65.62%] [G loss: 0.893812]\n",
      "931 [D loss: 0.585950, acc.: 70.31%] [G loss: 0.869771]\n",
      "932 [D loss: 0.612702, acc.: 81.25%] [G loss: 0.882284]\n",
      "933 [D loss: 0.597619, acc.: 78.12%] [G loss: 0.870495]\n",
      "934 [D loss: 0.613896, acc.: 67.19%] [G loss: 0.885463]\n",
      "935 [D loss: 0.626224, acc.: 71.88%] [G loss: 0.869095]\n",
      "936 [D loss: 0.614450, acc.: 68.75%] [G loss: 0.852143]\n",
      "937 [D loss: 0.616425, acc.: 75.00%] [G loss: 0.862357]\n",
      "938 [D loss: 0.582571, acc.: 81.25%] [G loss: 0.842014]\n",
      "939 [D loss: 0.603697, acc.: 64.06%] [G loss: 0.875964]\n",
      "940 [D loss: 0.608347, acc.: 73.44%] [G loss: 0.864508]\n",
      "941 [D loss: 0.666500, acc.: 54.69%] [G loss: 0.849160]\n",
      "942 [D loss: 0.601516, acc.: 65.62%] [G loss: 0.805592]\n",
      "943 [D loss: 0.636372, acc.: 68.75%] [G loss: 0.856369]\n",
      "944 [D loss: 0.613300, acc.: 68.75%] [G loss: 0.819643]\n",
      "945 [D loss: 0.527957, acc.: 85.94%] [G loss: 0.834803]\n",
      "946 [D loss: 0.586959, acc.: 78.12%] [G loss: 0.829042]\n",
      "947 [D loss: 0.600108, acc.: 78.12%] [G loss: 0.796419]\n",
      "948 [D loss: 0.595894, acc.: 73.44%] [G loss: 0.838705]\n",
      "949 [D loss: 0.561138, acc.: 82.81%] [G loss: 0.829153]\n",
      "950 [D loss: 0.642147, acc.: 57.81%] [G loss: 0.897203]\n",
      "951 [D loss: 0.659438, acc.: 64.06%] [G loss: 0.864824]\n",
      "952 [D loss: 0.625652, acc.: 67.19%] [G loss: 0.892792]\n",
      "953 [D loss: 0.638542, acc.: 65.62%] [G loss: 0.833691]\n",
      "954 [D loss: 0.631673, acc.: 59.38%] [G loss: 0.865722]\n",
      "955 [D loss: 0.637539, acc.: 62.50%] [G loss: 0.908264]\n",
      "956 [D loss: 0.591054, acc.: 79.69%] [G loss: 0.872860]\n",
      "957 [D loss: 0.634453, acc.: 67.19%] [G loss: 0.824096]\n",
      "958 [D loss: 0.620584, acc.: 68.75%] [G loss: 0.856420]\n",
      "959 [D loss: 0.647235, acc.: 62.50%] [G loss: 0.813022]\n",
      "960 [D loss: 0.589261, acc.: 76.56%] [G loss: 0.826265]\n",
      "961 [D loss: 0.646936, acc.: 65.62%] [G loss: 0.856415]\n",
      "962 [D loss: 0.621747, acc.: 70.31%] [G loss: 0.836974]\n",
      "963 [D loss: 0.607123, acc.: 64.06%] [G loss: 0.841589]\n",
      "964 [D loss: 0.613074, acc.: 70.31%] [G loss: 0.820471]\n",
      "965 [D loss: 0.650352, acc.: 53.12%] [G loss: 0.795745]\n",
      "966 [D loss: 0.608272, acc.: 65.62%] [G loss: 0.828031]\n",
      "967 [D loss: 0.644994, acc.: 67.19%] [G loss: 0.829890]\n",
      "968 [D loss: 0.595625, acc.: 71.88%] [G loss: 0.839028]\n",
      "969 [D loss: 0.647988, acc.: 60.94%] [G loss: 0.826413]\n",
      "970 [D loss: 0.608060, acc.: 71.88%] [G loss: 0.872787]\n",
      "971 [D loss: 0.576097, acc.: 79.69%] [G loss: 0.852417]\n",
      "972 [D loss: 0.648775, acc.: 67.19%] [G loss: 0.874205]\n",
      "973 [D loss: 0.623440, acc.: 67.19%] [G loss: 0.865223]\n",
      "974 [D loss: 0.605902, acc.: 75.00%] [G loss: 0.825074]\n",
      "975 [D loss: 0.623716, acc.: 65.62%] [G loss: 0.819861]\n",
      "976 [D loss: 0.597716, acc.: 71.88%] [G loss: 0.845784]\n",
      "977 [D loss: 0.599672, acc.: 75.00%] [G loss: 0.850391]\n",
      "978 [D loss: 0.596228, acc.: 73.44%] [G loss: 0.854783]\n",
      "979 [D loss: 0.628232, acc.: 59.38%] [G loss: 0.853921]\n",
      "980 [D loss: 0.590597, acc.: 75.00%] [G loss: 0.855653]\n",
      "981 [D loss: 0.606316, acc.: 71.88%] [G loss: 0.861632]\n",
      "982 [D loss: 0.595772, acc.: 71.88%] [G loss: 0.872136]\n",
      "983 [D loss: 0.606986, acc.: 70.31%] [G loss: 0.837897]\n",
      "984 [D loss: 0.606180, acc.: 67.19%] [G loss: 0.860082]\n",
      "985 [D loss: 0.594777, acc.: 78.12%] [G loss: 0.859079]\n",
      "986 [D loss: 0.600662, acc.: 76.56%] [G loss: 0.851665]\n",
      "987 [D loss: 0.635566, acc.: 70.31%] [G loss: 0.816244]\n",
      "988 [D loss: 0.627277, acc.: 65.62%] [G loss: 0.826898]\n",
      "989 [D loss: 0.606015, acc.: 71.88%] [G loss: 0.809205]\n",
      "990 [D loss: 0.596616, acc.: 67.19%] [G loss: 0.840225]\n",
      "991 [D loss: 0.578614, acc.: 75.00%] [G loss: 0.846248]\n",
      "992 [D loss: 0.636763, acc.: 67.19%] [G loss: 0.835305]\n",
      "993 [D loss: 0.561602, acc.: 75.00%] [G loss: 0.819198]\n",
      "994 [D loss: 0.616871, acc.: 62.50%] [G loss: 0.872358]\n",
      "995 [D loss: 0.588291, acc.: 78.12%] [G loss: 0.921540]\n",
      "996 [D loss: 0.582616, acc.: 75.00%] [G loss: 0.857149]\n",
      "997 [D loss: 0.602352, acc.: 76.56%] [G loss: 0.858529]\n",
      "998 [D loss: 0.612173, acc.: 70.31%] [G loss: 0.867852]\n",
      "999 [D loss: 0.593122, acc.: 68.75%] [G loss: 0.842908]\n",
      "1000 [D loss: 0.620721, acc.: 73.44%] [G loss: 0.904358]\n",
      "1001 [D loss: 0.612823, acc.: 68.75%] [G loss: 0.890806]\n",
      "1002 [D loss: 0.566681, acc.: 82.81%] [G loss: 0.893367]\n",
      "1003 [D loss: 0.585576, acc.: 79.69%] [G loss: 0.871904]\n",
      "1004 [D loss: 0.576986, acc.: 70.31%] [G loss: 0.920150]\n",
      "1005 [D loss: 0.567597, acc.: 76.56%] [G loss: 0.841631]\n",
      "1006 [D loss: 0.609275, acc.: 71.88%] [G loss: 0.903314]\n",
      "1007 [D loss: 0.641984, acc.: 65.62%] [G loss: 0.794583]\n",
      "1008 [D loss: 0.590268, acc.: 73.44%] [G loss: 0.822087]\n",
      "1009 [D loss: 0.613238, acc.: 65.62%] [G loss: 0.861287]\n",
      "1010 [D loss: 0.584701, acc.: 68.75%] [G loss: 0.916761]\n",
      "1011 [D loss: 0.634090, acc.: 60.94%] [G loss: 0.880830]\n",
      "1012 [D loss: 0.633895, acc.: 65.62%] [G loss: 0.841755]\n",
      "1013 [D loss: 0.606029, acc.: 75.00%] [G loss: 0.839195]\n",
      "1014 [D loss: 0.596230, acc.: 71.88%] [G loss: 0.851853]\n",
      "1015 [D loss: 0.634249, acc.: 75.00%] [G loss: 0.832207]\n",
      "1016 [D loss: 0.607764, acc.: 70.31%] [G loss: 0.834243]\n",
      "1017 [D loss: 0.609138, acc.: 73.44%] [G loss: 0.834090]\n",
      "1018 [D loss: 0.579836, acc.: 78.12%] [G loss: 0.805082]\n",
      "1019 [D loss: 0.583784, acc.: 73.44%] [G loss: 0.832557]\n",
      "1020 [D loss: 0.581121, acc.: 76.56%] [G loss: 0.899949]\n",
      "1021 [D loss: 0.637050, acc.: 62.50%] [G loss: 0.900648]\n",
      "1022 [D loss: 0.586225, acc.: 79.69%] [G loss: 0.894284]\n",
      "1023 [D loss: 0.596011, acc.: 73.44%] [G loss: 0.848649]\n",
      "1024 [D loss: 0.590377, acc.: 70.31%] [G loss: 0.869208]\n",
      "1025 [D loss: 0.598573, acc.: 70.31%] [G loss: 0.835599]\n",
      "1026 [D loss: 0.604777, acc.: 75.00%] [G loss: 0.916565]\n",
      "1027 [D loss: 0.608290, acc.: 67.19%] [G loss: 0.881101]\n",
      "1028 [D loss: 0.638507, acc.: 57.81%] [G loss: 0.825318]\n",
      "1029 [D loss: 0.621066, acc.: 68.75%] [G loss: 0.889424]\n",
      "1030 [D loss: 0.624424, acc.: 70.31%] [G loss: 0.932928]\n",
      "1031 [D loss: 0.603997, acc.: 73.44%] [G loss: 0.938890]\n",
      "1032 [D loss: 0.626866, acc.: 64.06%] [G loss: 0.799595]\n",
      "1033 [D loss: 0.632745, acc.: 59.38%] [G loss: 0.823075]\n",
      "1034 [D loss: 0.618005, acc.: 64.06%] [G loss: 0.805581]\n",
      "1035 [D loss: 0.621920, acc.: 68.75%] [G loss: 0.860658]\n",
      "1036 [D loss: 0.587168, acc.: 76.56%] [G loss: 0.859967]\n",
      "1037 [D loss: 0.589511, acc.: 79.69%] [G loss: 0.859353]\n",
      "1038 [D loss: 0.595298, acc.: 78.12%] [G loss: 0.824888]\n",
      "1039 [D loss: 0.592224, acc.: 76.56%] [G loss: 0.871057]\n",
      "1040 [D loss: 0.573778, acc.: 79.69%] [G loss: 0.851705]\n",
      "1041 [D loss: 0.576855, acc.: 73.44%] [G loss: 0.874063]\n",
      "1042 [D loss: 0.599574, acc.: 73.44%] [G loss: 0.871239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1043 [D loss: 0.533402, acc.: 81.25%] [G loss: 0.867863]\n",
      "1044 [D loss: 0.615307, acc.: 75.00%] [G loss: 0.883508]\n",
      "1045 [D loss: 0.630176, acc.: 70.31%] [G loss: 0.886828]\n",
      "1046 [D loss: 0.634090, acc.: 65.62%] [G loss: 0.848651]\n",
      "1047 [D loss: 0.589450, acc.: 71.88%] [G loss: 0.896905]\n",
      "1048 [D loss: 0.596544, acc.: 73.44%] [G loss: 0.978624]\n",
      "1049 [D loss: 0.609046, acc.: 76.56%] [G loss: 0.885562]\n",
      "1050 [D loss: 0.575073, acc.: 78.12%] [G loss: 0.896011]\n",
      "1051 [D loss: 0.607381, acc.: 78.12%] [G loss: 0.880600]\n",
      "1052 [D loss: 0.602677, acc.: 78.12%] [G loss: 0.877144]\n",
      "1053 [D loss: 0.575834, acc.: 82.81%] [G loss: 0.813057]\n",
      "1054 [D loss: 0.562738, acc.: 84.38%] [G loss: 0.865314]\n",
      "1055 [D loss: 0.610429, acc.: 76.56%] [G loss: 0.889814]\n",
      "1056 [D loss: 0.570774, acc.: 73.44%] [G loss: 0.910665]\n",
      "1057 [D loss: 0.580018, acc.: 73.44%] [G loss: 0.916853]\n",
      "1058 [D loss: 0.597490, acc.: 75.00%] [G loss: 0.868531]\n",
      "1059 [D loss: 0.590124, acc.: 71.88%] [G loss: 0.891223]\n",
      "1060 [D loss: 0.596855, acc.: 70.31%] [G loss: 0.857617]\n",
      "1061 [D loss: 0.582058, acc.: 75.00%] [G loss: 0.842318]\n",
      "1062 [D loss: 0.558231, acc.: 73.44%] [G loss: 0.854701]\n",
      "1063 [D loss: 0.628628, acc.: 64.06%] [G loss: 0.838348]\n",
      "1064 [D loss: 0.594812, acc.: 71.88%] [G loss: 0.817894]\n",
      "1065 [D loss: 0.566052, acc.: 79.69%] [G loss: 0.857307]\n",
      "1066 [D loss: 0.582256, acc.: 73.44%] [G loss: 0.919757]\n",
      "1067 [D loss: 0.618751, acc.: 57.81%] [G loss: 0.891902]\n",
      "1068 [D loss: 0.563860, acc.: 79.69%] [G loss: 0.878035]\n",
      "1069 [D loss: 0.577578, acc.: 73.44%] [G loss: 0.881558]\n",
      "1070 [D loss: 0.555694, acc.: 78.12%] [G loss: 0.888989]\n",
      "1071 [D loss: 0.583327, acc.: 65.62%] [G loss: 0.866136]\n",
      "1072 [D loss: 0.641293, acc.: 59.38%] [G loss: 0.822929]\n",
      "1073 [D loss: 0.615943, acc.: 68.75%] [G loss: 0.815453]\n",
      "1074 [D loss: 0.604143, acc.: 68.75%] [G loss: 0.817462]\n",
      "1075 [D loss: 0.602280, acc.: 64.06%] [G loss: 0.877627]\n",
      "1076 [D loss: 0.603034, acc.: 76.56%] [G loss: 0.849306]\n",
      "1077 [D loss: 0.568288, acc.: 79.69%] [G loss: 0.848261]\n",
      "1078 [D loss: 0.614213, acc.: 71.88%] [G loss: 0.901167]\n",
      "1079 [D loss: 0.579701, acc.: 76.56%] [G loss: 0.875648]\n",
      "1080 [D loss: 0.611781, acc.: 75.00%] [G loss: 0.836784]\n",
      "1081 [D loss: 0.615823, acc.: 70.31%] [G loss: 0.818940]\n",
      "1082 [D loss: 0.593081, acc.: 71.88%] [G loss: 0.812927]\n",
      "1083 [D loss: 0.564116, acc.: 76.56%] [G loss: 0.890806]\n",
      "1084 [D loss: 0.643703, acc.: 67.19%] [G loss: 0.834588]\n",
      "1085 [D loss: 0.603438, acc.: 70.31%] [G loss: 0.869163]\n",
      "1086 [D loss: 0.592014, acc.: 67.19%] [G loss: 0.872596]\n",
      "1087 [D loss: 0.580294, acc.: 75.00%] [G loss: 0.941548]\n",
      "1088 [D loss: 0.589173, acc.: 68.75%] [G loss: 0.940206]\n",
      "1089 [D loss: 0.606151, acc.: 67.19%] [G loss: 0.860909]\n",
      "1090 [D loss: 0.589470, acc.: 76.56%] [G loss: 0.904210]\n",
      "1091 [D loss: 0.661419, acc.: 59.38%] [G loss: 0.818921]\n",
      "1092 [D loss: 0.580333, acc.: 68.75%] [G loss: 0.866029]\n",
      "1093 [D loss: 0.607285, acc.: 65.62%] [G loss: 0.919992]\n",
      "1094 [D loss: 0.567358, acc.: 71.88%] [G loss: 0.903460]\n",
      "1095 [D loss: 0.616303, acc.: 68.75%] [G loss: 0.904071]\n",
      "1096 [D loss: 0.601475, acc.: 68.75%] [G loss: 0.861902]\n",
      "1097 [D loss: 0.592539, acc.: 75.00%] [G loss: 0.872018]\n",
      "1098 [D loss: 0.586201, acc.: 67.19%] [G loss: 0.913288]\n",
      "1099 [D loss: 0.613033, acc.: 71.88%] [G loss: 0.940682]\n",
      "1100 [D loss: 0.599354, acc.: 73.44%] [G loss: 0.898704]\n",
      "1101 [D loss: 0.595110, acc.: 78.12%] [G loss: 0.895718]\n",
      "1102 [D loss: 0.563509, acc.: 82.81%] [G loss: 0.870538]\n",
      "1103 [D loss: 0.616556, acc.: 64.06%] [G loss: 0.928620]\n",
      "1104 [D loss: 0.622609, acc.: 67.19%] [G loss: 0.935635]\n",
      "1105 [D loss: 0.594585, acc.: 73.44%] [G loss: 0.925646]\n",
      "1106 [D loss: 0.564252, acc.: 79.69%] [G loss: 0.920076]\n",
      "1107 [D loss: 0.552668, acc.: 79.69%] [G loss: 0.926567]\n",
      "1108 [D loss: 0.611097, acc.: 70.31%] [G loss: 0.878009]\n",
      "1109 [D loss: 0.622024, acc.: 65.62%] [G loss: 0.846556]\n",
      "1110 [D loss: 0.549692, acc.: 81.25%] [G loss: 0.889807]\n",
      "1111 [D loss: 0.598024, acc.: 70.31%] [G loss: 0.915004]\n",
      "1112 [D loss: 0.569711, acc.: 76.56%] [G loss: 0.888957]\n",
      "1113 [D loss: 0.611251, acc.: 73.44%] [G loss: 0.896399]\n",
      "1114 [D loss: 0.592689, acc.: 71.88%] [G loss: 0.884603]\n",
      "1115 [D loss: 0.599369, acc.: 70.31%] [G loss: 0.833608]\n",
      "1116 [D loss: 0.581198, acc.: 78.12%] [G loss: 0.848158]\n",
      "1117 [D loss: 0.565951, acc.: 73.44%] [G loss: 0.943310]\n",
      "1118 [D loss: 0.615521, acc.: 64.06%] [G loss: 0.916987]\n",
      "1119 [D loss: 0.611806, acc.: 70.31%] [G loss: 0.936032]\n",
      "1120 [D loss: 0.550674, acc.: 81.25%] [G loss: 0.904280]\n",
      "1121 [D loss: 0.585479, acc.: 71.88%] [G loss: 0.849935]\n",
      "1122 [D loss: 0.591466, acc.: 76.56%] [G loss: 0.863220]\n",
      "1123 [D loss: 0.589496, acc.: 68.75%] [G loss: 0.878579]\n",
      "1124 [D loss: 0.593041, acc.: 71.88%] [G loss: 0.930739]\n",
      "1125 [D loss: 0.551301, acc.: 79.69%] [G loss: 0.928604]\n",
      "1126 [D loss: 0.577231, acc.: 79.69%] [G loss: 0.933540]\n",
      "1127 [D loss: 0.582597, acc.: 71.88%] [G loss: 0.905450]\n",
      "1128 [D loss: 0.571124, acc.: 73.44%] [G loss: 0.875793]\n",
      "1129 [D loss: 0.568325, acc.: 78.12%] [G loss: 0.861304]\n",
      "1130 [D loss: 0.571863, acc.: 73.44%] [G loss: 0.884763]\n",
      "1131 [D loss: 0.614336, acc.: 70.31%] [G loss: 0.879191]\n",
      "1132 [D loss: 0.585382, acc.: 73.44%] [G loss: 0.938107]\n",
      "1133 [D loss: 0.607657, acc.: 65.62%] [G loss: 0.905663]\n",
      "1134 [D loss: 0.522659, acc.: 76.56%] [G loss: 0.961908]\n",
      "1135 [D loss: 0.627729, acc.: 57.81%] [G loss: 0.945572]\n",
      "1136 [D loss: 0.538347, acc.: 81.25%] [G loss: 0.921584]\n",
      "1137 [D loss: 0.575637, acc.: 71.88%] [G loss: 0.935952]\n",
      "1138 [D loss: 0.599231, acc.: 75.00%] [G loss: 0.933128]\n",
      "1139 [D loss: 0.623810, acc.: 70.31%] [G loss: 0.898103]\n",
      "1140 [D loss: 0.567876, acc.: 79.69%] [G loss: 0.867643]\n",
      "1141 [D loss: 0.611854, acc.: 65.62%] [G loss: 0.857017]\n",
      "1142 [D loss: 0.583043, acc.: 68.75%] [G loss: 0.844818]\n",
      "1143 [D loss: 0.612281, acc.: 70.31%] [G loss: 0.856584]\n",
      "1144 [D loss: 0.576406, acc.: 81.25%] [G loss: 0.845205]\n",
      "1145 [D loss: 0.618840, acc.: 67.19%] [G loss: 0.890724]\n",
      "1146 [D loss: 0.577816, acc.: 79.69%] [G loss: 0.930323]\n",
      "1147 [D loss: 0.592056, acc.: 67.19%] [G loss: 0.957839]\n",
      "1148 [D loss: 0.553028, acc.: 85.94%] [G loss: 0.952032]\n",
      "1149 [D loss: 0.617078, acc.: 75.00%] [G loss: 0.943809]\n",
      "1150 [D loss: 0.552654, acc.: 79.69%] [G loss: 0.905599]\n",
      "1151 [D loss: 0.580104, acc.: 78.12%] [G loss: 0.876430]\n",
      "1152 [D loss: 0.588181, acc.: 78.12%] [G loss: 0.923440]\n",
      "1153 [D loss: 0.604617, acc.: 76.56%] [G loss: 0.871314]\n",
      "1154 [D loss: 0.550711, acc.: 76.56%] [G loss: 0.918371]\n",
      "1155 [D loss: 0.578316, acc.: 81.25%] [G loss: 0.872823]\n",
      "1156 [D loss: 0.580355, acc.: 73.44%] [G loss: 0.894278]\n",
      "1157 [D loss: 0.630975, acc.: 62.50%] [G loss: 0.934801]\n",
      "1158 [D loss: 0.545533, acc.: 84.38%] [G loss: 0.862421]\n",
      "1159 [D loss: 0.566731, acc.: 78.12%] [G loss: 0.913278]\n",
      "1160 [D loss: 0.539660, acc.: 87.50%] [G loss: 0.854199]\n",
      "1161 [D loss: 0.546820, acc.: 71.88%] [G loss: 0.783372]\n",
      "1162 [D loss: 0.554108, acc.: 71.88%] [G loss: 0.920623]\n",
      "1163 [D loss: 0.584534, acc.: 70.31%] [G loss: 0.864141]\n",
      "1164 [D loss: 0.599686, acc.: 64.06%] [G loss: 0.845389]\n",
      "1165 [D loss: 0.591909, acc.: 76.56%] [G loss: 0.878973]\n",
      "1166 [D loss: 0.559900, acc.: 79.69%] [G loss: 0.962137]\n",
      "1167 [D loss: 0.591758, acc.: 67.19%] [G loss: 0.955424]\n",
      "1168 [D loss: 0.590062, acc.: 76.56%] [G loss: 0.931431]\n",
      "1169 [D loss: 0.616725, acc.: 64.06%] [G loss: 0.913385]\n",
      "1170 [D loss: 0.548639, acc.: 76.56%] [G loss: 0.890726]\n",
      "1171 [D loss: 0.615445, acc.: 65.62%] [G loss: 0.937639]\n",
      "1172 [D loss: 0.603721, acc.: 73.44%] [G loss: 0.888120]\n",
      "1173 [D loss: 0.554643, acc.: 79.69%] [G loss: 0.911598]\n",
      "1174 [D loss: 0.628046, acc.: 56.25%] [G loss: 0.925465]\n",
      "1175 [D loss: 0.558539, acc.: 81.25%] [G loss: 0.876433]\n",
      "1176 [D loss: 0.612896, acc.: 70.31%] [G loss: 0.905550]\n",
      "1177 [D loss: 0.594191, acc.: 75.00%] [G loss: 0.902555]\n",
      "1178 [D loss: 0.523367, acc.: 84.38%] [G loss: 0.935035]\n",
      "1179 [D loss: 0.546637, acc.: 78.12%] [G loss: 0.911983]\n",
      "1180 [D loss: 0.619916, acc.: 65.62%] [G loss: 0.941257]\n",
      "1181 [D loss: 0.621821, acc.: 70.31%] [G loss: 0.913673]\n",
      "1182 [D loss: 0.523189, acc.: 90.62%] [G loss: 0.923801]\n",
      "1183 [D loss: 0.562670, acc.: 79.69%] [G loss: 0.898175]\n",
      "1184 [D loss: 0.597468, acc.: 71.88%] [G loss: 0.927199]\n",
      "1185 [D loss: 0.593571, acc.: 68.75%] [G loss: 0.877005]\n",
      "1186 [D loss: 0.607203, acc.: 68.75%] [G loss: 0.963394]\n",
      "1187 [D loss: 0.573493, acc.: 71.88%] [G loss: 0.918710]\n",
      "1188 [D loss: 0.560367, acc.: 75.00%] [G loss: 0.940773]\n",
      "1189 [D loss: 0.545272, acc.: 75.00%] [G loss: 0.932651]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190 [D loss: 0.606344, acc.: 70.31%] [G loss: 0.923671]\n",
      "1191 [D loss: 0.575041, acc.: 75.00%] [G loss: 0.905266]\n",
      "1192 [D loss: 0.587065, acc.: 76.56%] [G loss: 0.874405]\n",
      "1193 [D loss: 0.545486, acc.: 76.56%] [G loss: 0.865790]\n",
      "1194 [D loss: 0.562548, acc.: 78.12%] [G loss: 0.846280]\n",
      "1195 [D loss: 0.586686, acc.: 71.88%] [G loss: 0.939962]\n",
      "1196 [D loss: 0.636854, acc.: 65.62%] [G loss: 0.927989]\n",
      "1197 [D loss: 0.602915, acc.: 68.75%] [G loss: 0.848031]\n",
      "1198 [D loss: 0.617540, acc.: 71.88%] [G loss: 0.869676]\n",
      "1199 [D loss: 0.643670, acc.: 64.06%] [G loss: 0.886255]\n",
      "1200 [D loss: 0.571947, acc.: 76.56%] [G loss: 0.858702]\n",
      "1201 [D loss: 0.577441, acc.: 79.69%] [G loss: 0.844701]\n",
      "1202 [D loss: 0.587471, acc.: 70.31%] [G loss: 0.896287]\n",
      "1203 [D loss: 0.614216, acc.: 67.19%] [G loss: 0.854489]\n",
      "1204 [D loss: 0.655696, acc.: 57.81%] [G loss: 0.891528]\n",
      "1205 [D loss: 0.563457, acc.: 76.56%] [G loss: 0.954401]\n",
      "1206 [D loss: 0.600267, acc.: 67.19%] [G loss: 0.873351]\n",
      "1207 [D loss: 0.614118, acc.: 68.75%] [G loss: 0.963869]\n",
      "1208 [D loss: 0.665054, acc.: 53.12%] [G loss: 0.949279]\n",
      "1209 [D loss: 0.644831, acc.: 64.06%] [G loss: 0.887848]\n",
      "1210 [D loss: 0.636878, acc.: 65.62%] [G loss: 0.865759]\n",
      "1211 [D loss: 0.600018, acc.: 81.25%] [G loss: 0.892111]\n",
      "1212 [D loss: 0.613138, acc.: 64.06%] [G loss: 0.845331]\n",
      "1213 [D loss: 0.518576, acc.: 85.94%] [G loss: 0.823961]\n",
      "1214 [D loss: 0.571684, acc.: 70.31%] [G loss: 0.864670]\n",
      "1215 [D loss: 0.584214, acc.: 70.31%] [G loss: 0.851812]\n",
      "1216 [D loss: 0.564526, acc.: 76.56%] [G loss: 0.879801]\n",
      "1217 [D loss: 0.637636, acc.: 67.19%] [G loss: 0.828087]\n",
      "1218 [D loss: 0.575999, acc.: 73.44%] [G loss: 0.934007]\n",
      "1219 [D loss: 0.649279, acc.: 57.81%] [G loss: 0.882404]\n",
      "1220 [D loss: 0.598070, acc.: 70.31%] [G loss: 0.924615]\n",
      "1221 [D loss: 0.552262, acc.: 75.00%] [G loss: 0.930715]\n",
      "1222 [D loss: 0.568888, acc.: 79.69%] [G loss: 0.961250]\n",
      "1223 [D loss: 0.588692, acc.: 73.44%] [G loss: 0.910326]\n",
      "1224 [D loss: 0.613145, acc.: 67.19%] [G loss: 0.928023]\n",
      "1225 [D loss: 0.622622, acc.: 59.38%] [G loss: 0.959713]\n",
      "1226 [D loss: 0.600029, acc.: 75.00%] [G loss: 0.868986]\n",
      "1227 [D loss: 0.562912, acc.: 73.44%] [G loss: 0.905475]\n",
      "1228 [D loss: 0.574242, acc.: 75.00%] [G loss: 0.874535]\n",
      "1229 [D loss: 0.592988, acc.: 75.00%] [G loss: 0.920346]\n",
      "1230 [D loss: 0.604960, acc.: 68.75%] [G loss: 0.928715]\n",
      "1231 [D loss: 0.617623, acc.: 65.62%] [G loss: 0.951077]\n",
      "1232 [D loss: 0.582374, acc.: 73.44%] [G loss: 0.915361]\n",
      "1233 [D loss: 0.631463, acc.: 68.75%] [G loss: 0.846561]\n",
      "1234 [D loss: 0.593211, acc.: 73.44%] [G loss: 0.860900]\n",
      "1235 [D loss: 0.586665, acc.: 73.44%] [G loss: 0.837060]\n",
      "1236 [D loss: 0.588900, acc.: 70.31%] [G loss: 0.876058]\n",
      "1237 [D loss: 0.620106, acc.: 65.62%] [G loss: 0.873465]\n",
      "1238 [D loss: 0.600179, acc.: 67.19%] [G loss: 0.936586]\n",
      "1239 [D loss: 0.607282, acc.: 71.88%] [G loss: 0.922158]\n",
      "1240 [D loss: 0.643565, acc.: 60.94%] [G loss: 0.857859]\n",
      "1241 [D loss: 0.558296, acc.: 71.88%] [G loss: 0.981793]\n",
      "1242 [D loss: 0.582274, acc.: 67.19%] [G loss: 1.031443]\n",
      "1243 [D loss: 0.635718, acc.: 70.31%] [G loss: 0.912254]\n",
      "1244 [D loss: 0.603902, acc.: 67.19%] [G loss: 0.922000]\n",
      "1245 [D loss: 0.600879, acc.: 68.75%] [G loss: 0.982527]\n",
      "1246 [D loss: 0.643144, acc.: 59.38%] [G loss: 0.868606]\n",
      "1247 [D loss: 0.597849, acc.: 64.06%] [G loss: 0.844518]\n",
      "1248 [D loss: 0.633130, acc.: 64.06%] [G loss: 0.855015]\n",
      "1249 [D loss: 0.570866, acc.: 70.31%] [G loss: 0.912140]\n",
      "1250 [D loss: 0.548678, acc.: 78.12%] [G loss: 0.874446]\n",
      "1251 [D loss: 0.612415, acc.: 68.75%] [G loss: 0.892067]\n",
      "1252 [D loss: 0.544408, acc.: 78.12%] [G loss: 0.937073]\n",
      "1253 [D loss: 0.578089, acc.: 75.00%] [G loss: 0.994511]\n",
      "1254 [D loss: 0.611835, acc.: 62.50%] [G loss: 0.930191]\n",
      "1255 [D loss: 0.554830, acc.: 78.12%] [G loss: 0.981157]\n",
      "1256 [D loss: 0.597253, acc.: 68.75%] [G loss: 0.955189]\n",
      "1257 [D loss: 0.537424, acc.: 78.12%] [G loss: 0.991514]\n",
      "1258 [D loss: 0.623792, acc.: 67.19%] [G loss: 0.901922]\n",
      "1259 [D loss: 0.579403, acc.: 70.31%] [G loss: 0.919941]\n",
      "1260 [D loss: 0.614528, acc.: 64.06%] [G loss: 0.896776]\n",
      "1261 [D loss: 0.567186, acc.: 71.88%] [G loss: 0.943837]\n",
      "1262 [D loss: 0.581503, acc.: 70.31%] [G loss: 0.952198]\n",
      "1263 [D loss: 0.565198, acc.: 73.44%] [G loss: 0.936087]\n",
      "1264 [D loss: 0.548848, acc.: 76.56%] [G loss: 0.884194]\n",
      "1265 [D loss: 0.502275, acc.: 84.38%] [G loss: 0.906677]\n",
      "1266 [D loss: 0.594995, acc.: 71.88%] [G loss: 0.914067]\n",
      "1267 [D loss: 0.593136, acc.: 73.44%] [G loss: 0.882715]\n",
      "1268 [D loss: 0.577118, acc.: 76.56%] [G loss: 0.924012]\n",
      "1269 [D loss: 0.592292, acc.: 75.00%] [G loss: 0.978285]\n",
      "1270 [D loss: 0.614608, acc.: 67.19%] [G loss: 0.867566]\n",
      "1271 [D loss: 0.608047, acc.: 65.62%] [G loss: 0.944118]\n",
      "1272 [D loss: 0.566196, acc.: 73.44%] [G loss: 0.991510]\n",
      "1273 [D loss: 0.605038, acc.: 71.88%] [G loss: 0.899675]\n",
      "1274 [D loss: 0.543706, acc.: 82.81%] [G loss: 0.918736]\n",
      "1275 [D loss: 0.553192, acc.: 78.12%] [G loss: 0.961377]\n",
      "1276 [D loss: 0.477067, acc.: 89.06%] [G loss: 0.924071]\n",
      "1277 [D loss: 0.640859, acc.: 56.25%] [G loss: 0.900106]\n",
      "1278 [D loss: 0.614282, acc.: 71.88%] [G loss: 0.897062]\n",
      "1279 [D loss: 0.563677, acc.: 71.88%] [G loss: 0.952082]\n",
      "1280 [D loss: 0.558639, acc.: 73.44%] [G loss: 0.903339]\n",
      "1281 [D loss: 0.582538, acc.: 71.88%] [G loss: 0.960758]\n",
      "1282 [D loss: 0.581616, acc.: 76.56%] [G loss: 0.951130]\n",
      "1283 [D loss: 0.538328, acc.: 84.38%] [G loss: 0.926735]\n",
      "1284 [D loss: 0.596954, acc.: 67.19%] [G loss: 0.903500]\n",
      "1285 [D loss: 0.558172, acc.: 79.69%] [G loss: 1.029419]\n",
      "1286 [D loss: 0.555942, acc.: 82.81%] [G loss: 1.009552]\n",
      "1287 [D loss: 0.572195, acc.: 68.75%] [G loss: 0.955722]\n",
      "1288 [D loss: 0.574045, acc.: 73.44%] [G loss: 0.932633]\n",
      "1289 [D loss: 0.560077, acc.: 76.56%] [G loss: 0.946600]\n",
      "1290 [D loss: 0.560303, acc.: 78.12%] [G loss: 0.932461]\n",
      "1291 [D loss: 0.585135, acc.: 68.75%] [G loss: 0.960014]\n",
      "1292 [D loss: 0.577327, acc.: 73.44%] [G loss: 0.929756]\n",
      "1293 [D loss: 0.529493, acc.: 76.56%] [G loss: 0.926790]\n",
      "1294 [D loss: 0.550819, acc.: 79.69%] [G loss: 0.941932]\n",
      "1295 [D loss: 0.551821, acc.: 79.69%] [G loss: 0.855316]\n",
      "1296 [D loss: 0.545504, acc.: 84.38%] [G loss: 0.952979]\n",
      "1297 [D loss: 0.641686, acc.: 70.31%] [G loss: 0.897102]\n",
      "1298 [D loss: 0.561837, acc.: 75.00%] [G loss: 0.946824]\n",
      "1299 [D loss: 0.591699, acc.: 71.88%] [G loss: 0.939577]\n",
      "1300 [D loss: 0.606766, acc.: 67.19%] [G loss: 0.927227]\n",
      "1301 [D loss: 0.567939, acc.: 84.38%] [G loss: 0.960478]\n",
      "1302 [D loss: 0.586460, acc.: 68.75%] [G loss: 0.925640]\n",
      "1303 [D loss: 0.587400, acc.: 62.50%] [G loss: 0.969395]\n",
      "1304 [D loss: 0.606398, acc.: 79.69%] [G loss: 0.998445]\n",
      "1305 [D loss: 0.593577, acc.: 78.12%] [G loss: 0.997343]\n",
      "1306 [D loss: 0.592094, acc.: 70.31%] [G loss: 0.939965]\n",
      "1307 [D loss: 0.600367, acc.: 70.31%] [G loss: 0.913335]\n",
      "1308 [D loss: 0.576125, acc.: 81.25%] [G loss: 0.964633]\n",
      "1309 [D loss: 0.559327, acc.: 76.56%] [G loss: 0.931350]\n",
      "1310 [D loss: 0.620185, acc.: 70.31%] [G loss: 0.909783]\n",
      "1311 [D loss: 0.531518, acc.: 82.81%] [G loss: 0.909643]\n",
      "1312 [D loss: 0.570563, acc.: 71.88%] [G loss: 0.931279]\n",
      "1313 [D loss: 0.529498, acc.: 81.25%] [G loss: 0.948329]\n",
      "1314 [D loss: 0.565046, acc.: 85.94%] [G loss: 0.976701]\n",
      "1315 [D loss: 0.639418, acc.: 60.94%] [G loss: 0.967727]\n",
      "1316 [D loss: 0.571950, acc.: 78.12%] [G loss: 0.881875]\n",
      "1317 [D loss: 0.593197, acc.: 70.31%] [G loss: 0.878185]\n",
      "1318 [D loss: 0.533585, acc.: 75.00%] [G loss: 0.917610]\n",
      "1319 [D loss: 0.582531, acc.: 71.88%] [G loss: 0.911817]\n",
      "1320 [D loss: 0.635362, acc.: 60.94%] [G loss: 0.940153]\n",
      "1321 [D loss: 0.533945, acc.: 81.25%] [G loss: 0.933285]\n",
      "1322 [D loss: 0.596630, acc.: 71.88%] [G loss: 0.907170]\n",
      "1323 [D loss: 0.580823, acc.: 75.00%] [G loss: 0.894595]\n",
      "1324 [D loss: 0.601297, acc.: 65.62%] [G loss: 0.929395]\n",
      "1325 [D loss: 0.582175, acc.: 71.88%] [G loss: 0.962630]\n",
      "1326 [D loss: 0.565384, acc.: 64.06%] [G loss: 0.903384]\n",
      "1327 [D loss: 0.579719, acc.: 73.44%] [G loss: 0.938935]\n",
      "1328 [D loss: 0.572530, acc.: 70.31%] [G loss: 1.001859]\n",
      "1329 [D loss: 0.550623, acc.: 76.56%] [G loss: 1.033024]\n",
      "1330 [D loss: 0.573495, acc.: 75.00%] [G loss: 0.946563]\n",
      "1331 [D loss: 0.627133, acc.: 57.81%] [G loss: 0.907649]\n",
      "1332 [D loss: 0.600235, acc.: 68.75%] [G loss: 0.971353]\n",
      "1333 [D loss: 0.567105, acc.: 75.00%] [G loss: 0.880841]\n",
      "1334 [D loss: 0.566548, acc.: 81.25%] [G loss: 0.897634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1335 [D loss: 0.544766, acc.: 75.00%] [G loss: 0.858826]\n",
      "1336 [D loss: 0.554561, acc.: 73.44%] [G loss: 0.857268]\n",
      "1337 [D loss: 0.605954, acc.: 68.75%] [G loss: 0.904443]\n",
      "1338 [D loss: 0.513795, acc.: 82.81%] [G loss: 0.977086]\n",
      "1339 [D loss: 0.609055, acc.: 70.31%] [G loss: 0.945028]\n",
      "1340 [D loss: 0.552506, acc.: 71.88%] [G loss: 0.978092]\n",
      "1341 [D loss: 0.570330, acc.: 78.12%] [G loss: 0.911319]\n",
      "1342 [D loss: 0.558586, acc.: 73.44%] [G loss: 0.953460]\n",
      "1343 [D loss: 0.612345, acc.: 68.75%] [G loss: 0.915136]\n",
      "1344 [D loss: 0.594623, acc.: 70.31%] [G loss: 0.983860]\n",
      "1345 [D loss: 0.572014, acc.: 75.00%] [G loss: 0.859657]\n",
      "1346 [D loss: 0.565935, acc.: 79.69%] [G loss: 0.978131]\n",
      "1347 [D loss: 0.552474, acc.: 84.38%] [G loss: 0.866435]\n",
      "1348 [D loss: 0.589500, acc.: 79.69%] [G loss: 0.903364]\n",
      "1349 [D loss: 0.567855, acc.: 76.56%] [G loss: 0.917862]\n",
      "1350 [D loss: 0.597927, acc.: 67.19%] [G loss: 0.920747]\n",
      "1351 [D loss: 0.551589, acc.: 78.12%] [G loss: 0.945583]\n",
      "1352 [D loss: 0.553177, acc.: 79.69%] [G loss: 0.920910]\n",
      "1353 [D loss: 0.569959, acc.: 78.12%] [G loss: 0.940123]\n",
      "1354 [D loss: 0.589279, acc.: 68.75%] [G loss: 0.952002]\n",
      "1355 [D loss: 0.579947, acc.: 78.12%] [G loss: 0.927335]\n",
      "1356 [D loss: 0.519771, acc.: 82.81%] [G loss: 0.903809]\n",
      "1357 [D loss: 0.562750, acc.: 73.44%] [G loss: 0.984093]\n",
      "1358 [D loss: 0.505974, acc.: 79.69%] [G loss: 0.930776]\n",
      "1359 [D loss: 0.548161, acc.: 75.00%] [G loss: 0.942334]\n",
      "1360 [D loss: 0.591792, acc.: 73.44%] [G loss: 0.987068]\n",
      "1361 [D loss: 0.536764, acc.: 75.00%] [G loss: 0.922191]\n",
      "1362 [D loss: 0.591721, acc.: 71.88%] [G loss: 0.922325]\n",
      "1363 [D loss: 0.573668, acc.: 71.88%] [G loss: 0.877527]\n",
      "1364 [D loss: 0.581655, acc.: 73.44%] [G loss: 0.951267]\n",
      "1365 [D loss: 0.619956, acc.: 68.75%] [G loss: 0.916111]\n",
      "1366 [D loss: 0.546513, acc.: 75.00%] [G loss: 0.968377]\n",
      "1367 [D loss: 0.590420, acc.: 71.88%] [G loss: 1.016646]\n",
      "1368 [D loss: 0.590139, acc.: 71.88%] [G loss: 0.905858]\n",
      "1369 [D loss: 0.509888, acc.: 79.69%] [G loss: 0.932009]\n",
      "1370 [D loss: 0.617907, acc.: 65.62%] [G loss: 1.029425]\n",
      "1371 [D loss: 0.537493, acc.: 81.25%] [G loss: 1.009607]\n",
      "1372 [D loss: 0.522419, acc.: 79.69%] [G loss: 0.982439]\n",
      "1373 [D loss: 0.557031, acc.: 73.44%] [G loss: 1.010916]\n",
      "1374 [D loss: 0.546818, acc.: 76.56%] [G loss: 0.994821]\n",
      "1375 [D loss: 0.541902, acc.: 75.00%] [G loss: 0.993334]\n",
      "1376 [D loss: 0.532587, acc.: 79.69%] [G loss: 0.946127]\n",
      "1377 [D loss: 0.537264, acc.: 78.12%] [G loss: 0.952819]\n",
      "1378 [D loss: 0.571629, acc.: 68.75%] [G loss: 0.977836]\n",
      "1379 [D loss: 0.612632, acc.: 67.19%] [G loss: 0.942688]\n",
      "1380 [D loss: 0.569727, acc.: 70.31%] [G loss: 0.913858]\n",
      "1381 [D loss: 0.541732, acc.: 71.88%] [G loss: 0.901362]\n",
      "1382 [D loss: 0.569341, acc.: 73.44%] [G loss: 0.941026]\n",
      "1383 [D loss: 0.576889, acc.: 73.44%] [G loss: 0.996033]\n",
      "1384 [D loss: 0.585411, acc.: 65.62%] [G loss: 1.058801]\n",
      "1385 [D loss: 0.620914, acc.: 68.75%] [G loss: 0.949614]\n",
      "1386 [D loss: 0.586593, acc.: 65.62%] [G loss: 0.993730]\n",
      "1387 [D loss: 0.612355, acc.: 70.31%] [G loss: 0.849965]\n",
      "1388 [D loss: 0.554994, acc.: 76.56%] [G loss: 0.889783]\n",
      "1389 [D loss: 0.565493, acc.: 70.31%] [G loss: 1.029977]\n",
      "1390 [D loss: 0.574152, acc.: 79.69%] [G loss: 0.945571]\n",
      "1391 [D loss: 0.568351, acc.: 67.19%] [G loss: 0.904520]\n",
      "1392 [D loss: 0.529356, acc.: 78.12%] [G loss: 0.934121]\n",
      "1393 [D loss: 0.571451, acc.: 75.00%] [G loss: 0.920709]\n",
      "1394 [D loss: 0.604811, acc.: 70.31%] [G loss: 0.954623]\n",
      "1395 [D loss: 0.587017, acc.: 75.00%] [G loss: 0.951991]\n",
      "1396 [D loss: 0.576194, acc.: 68.75%] [G loss: 0.979919]\n",
      "1397 [D loss: 0.542067, acc.: 79.69%] [G loss: 1.046455]\n",
      "1398 [D loss: 0.598432, acc.: 70.31%] [G loss: 0.927411]\n",
      "1399 [D loss: 0.577039, acc.: 70.31%] [G loss: 0.954360]\n",
      "1400 [D loss: 0.569114, acc.: 73.44%] [G loss: 1.011452]\n",
      "1401 [D loss: 0.558302, acc.: 70.31%] [G loss: 1.054855]\n",
      "1402 [D loss: 0.488714, acc.: 87.50%] [G loss: 1.044551]\n",
      "1403 [D loss: 0.529874, acc.: 81.25%] [G loss: 1.073174]\n",
      "1404 [D loss: 0.523159, acc.: 81.25%] [G loss: 0.992604]\n",
      "1405 [D loss: 0.594531, acc.: 67.19%] [G loss: 0.980758]\n",
      "1406 [D loss: 0.542842, acc.: 71.88%] [G loss: 1.104943]\n",
      "1407 [D loss: 0.609432, acc.: 60.94%] [G loss: 0.962210]\n",
      "1408 [D loss: 0.569512, acc.: 70.31%] [G loss: 0.962475]\n",
      "1409 [D loss: 0.539717, acc.: 78.12%] [G loss: 1.003018]\n",
      "1410 [D loss: 0.555819, acc.: 76.56%] [G loss: 0.973211]\n",
      "1411 [D loss: 0.594412, acc.: 62.50%] [G loss: 0.981426]\n",
      "1412 [D loss: 0.598390, acc.: 67.19%] [G loss: 0.949346]\n",
      "1413 [D loss: 0.590078, acc.: 75.00%] [G loss: 0.984585]\n",
      "1414 [D loss: 0.569105, acc.: 70.31%] [G loss: 0.906129]\n",
      "1415 [D loss: 0.526100, acc.: 81.25%] [G loss: 1.012783]\n",
      "1416 [D loss: 0.537849, acc.: 82.81%] [G loss: 1.039255]\n",
      "1417 [D loss: 0.558540, acc.: 76.56%] [G loss: 0.962885]\n",
      "1418 [D loss: 0.576611, acc.: 71.88%] [G loss: 1.001301]\n",
      "1419 [D loss: 0.565571, acc.: 73.44%] [G loss: 0.994226]\n",
      "1420 [D loss: 0.484373, acc.: 78.12%] [G loss: 1.039863]\n",
      "1421 [D loss: 0.543662, acc.: 78.12%] [G loss: 0.963206]\n",
      "1422 [D loss: 0.566001, acc.: 81.25%] [G loss: 1.029616]\n",
      "1423 [D loss: 0.583000, acc.: 65.62%] [G loss: 1.022996]\n",
      "1424 [D loss: 0.579542, acc.: 76.56%] [G loss: 0.952732]\n",
      "1425 [D loss: 0.506876, acc.: 84.38%] [G loss: 0.960001]\n",
      "1426 [D loss: 0.602380, acc.: 68.75%] [G loss: 0.888663]\n",
      "1427 [D loss: 0.582842, acc.: 68.75%] [G loss: 0.958516]\n",
      "1428 [D loss: 0.512569, acc.: 81.25%] [G loss: 0.942197]\n",
      "1429 [D loss: 0.561882, acc.: 71.88%] [G loss: 1.032119]\n",
      "1430 [D loss: 0.500548, acc.: 79.69%] [G loss: 1.016463]\n",
      "1431 [D loss: 0.561927, acc.: 68.75%] [G loss: 1.080572]\n",
      "1432 [D loss: 0.556819, acc.: 76.56%] [G loss: 0.966254]\n",
      "1433 [D loss: 0.596602, acc.: 70.31%] [G loss: 0.950411]\n",
      "1434 [D loss: 0.564224, acc.: 70.31%] [G loss: 0.971791]\n",
      "1435 [D loss: 0.549437, acc.: 70.31%] [G loss: 0.983238]\n",
      "1436 [D loss: 0.579635, acc.: 71.88%] [G loss: 1.013052]\n",
      "1437 [D loss: 0.482118, acc.: 87.50%] [G loss: 1.054136]\n",
      "1438 [D loss: 0.578798, acc.: 65.62%] [G loss: 1.039020]\n",
      "1439 [D loss: 0.611590, acc.: 62.50%] [G loss: 0.957883]\n",
      "1440 [D loss: 0.526453, acc.: 81.25%] [G loss: 1.040280]\n",
      "1441 [D loss: 0.596617, acc.: 68.75%] [G loss: 0.965031]\n",
      "1442 [D loss: 0.498670, acc.: 82.81%] [G loss: 0.969966]\n",
      "1443 [D loss: 0.506451, acc.: 78.12%] [G loss: 1.089143]\n",
      "1444 [D loss: 0.568139, acc.: 65.62%] [G loss: 1.035654]\n",
      "1445 [D loss: 0.587125, acc.: 64.06%] [G loss: 1.041264]\n",
      "1446 [D loss: 0.652393, acc.: 60.94%] [G loss: 1.083028]\n",
      "1447 [D loss: 0.623052, acc.: 62.50%] [G loss: 1.020381]\n",
      "1448 [D loss: 0.558287, acc.: 76.56%] [G loss: 1.016798]\n",
      "1449 [D loss: 0.566465, acc.: 76.56%] [G loss: 0.975889]\n",
      "1450 [D loss: 0.581622, acc.: 73.44%] [G loss: 0.936723]\n",
      "1451 [D loss: 0.504678, acc.: 81.25%] [G loss: 0.933265]\n",
      "1452 [D loss: 0.564202, acc.: 73.44%] [G loss: 0.994385]\n",
      "1453 [D loss: 0.651591, acc.: 65.62%] [G loss: 0.906882]\n",
      "1454 [D loss: 0.570850, acc.: 75.00%] [G loss: 0.856990]\n",
      "1455 [D loss: 0.619888, acc.: 60.94%] [G loss: 1.007045]\n",
      "1456 [D loss: 0.578535, acc.: 71.88%] [G loss: 0.946177]\n",
      "1457 [D loss: 0.548347, acc.: 73.44%] [G loss: 0.973119]\n",
      "1458 [D loss: 0.666921, acc.: 64.06%] [G loss: 1.006398]\n",
      "1459 [D loss: 0.592244, acc.: 68.75%] [G loss: 0.874272]\n",
      "1460 [D loss: 0.554684, acc.: 79.69%] [G loss: 0.929917]\n",
      "1461 [D loss: 0.558420, acc.: 73.44%] [G loss: 0.977054]\n",
      "1462 [D loss: 0.562803, acc.: 70.31%] [G loss: 1.017590]\n",
      "1463 [D loss: 0.571772, acc.: 71.88%] [G loss: 1.009296]\n",
      "1464 [D loss: 0.582313, acc.: 75.00%] [G loss: 1.064105]\n",
      "1465 [D loss: 0.547265, acc.: 76.56%] [G loss: 1.015313]\n",
      "1466 [D loss: 0.599775, acc.: 70.31%] [G loss: 1.000063]\n",
      "1467 [D loss: 0.623101, acc.: 78.12%] [G loss: 0.936001]\n",
      "1468 [D loss: 0.589933, acc.: 73.44%] [G loss: 0.994599]\n",
      "1469 [D loss: 0.551637, acc.: 76.56%] [G loss: 1.047067]\n",
      "1470 [D loss: 0.587064, acc.: 70.31%] [G loss: 1.051522]\n",
      "1471 [D loss: 0.597879, acc.: 67.19%] [G loss: 0.993181]\n",
      "1472 [D loss: 0.562042, acc.: 76.56%] [G loss: 0.947816]\n",
      "1473 [D loss: 0.568887, acc.: 71.88%] [G loss: 0.965787]\n",
      "1474 [D loss: 0.566901, acc.: 70.31%] [G loss: 0.988444]\n",
      "1475 [D loss: 0.532117, acc.: 76.56%] [G loss: 0.939106]\n",
      "1476 [D loss: 0.668669, acc.: 56.25%] [G loss: 0.989337]\n",
      "1477 [D loss: 0.597451, acc.: 73.44%] [G loss: 0.927800]\n",
      "1478 [D loss: 0.593440, acc.: 76.56%] [G loss: 0.960779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1479 [D loss: 0.551558, acc.: 76.56%] [G loss: 0.940816]\n",
      "1480 [D loss: 0.602789, acc.: 68.75%] [G loss: 1.055015]\n",
      "1481 [D loss: 0.563152, acc.: 73.44%] [G loss: 1.050992]\n",
      "1482 [D loss: 0.567038, acc.: 79.69%] [G loss: 0.985996]\n",
      "1483 [D loss: 0.581275, acc.: 71.88%] [G loss: 0.984106]\n",
      "1484 [D loss: 0.586942, acc.: 75.00%] [G loss: 0.947874]\n",
      "1485 [D loss: 0.561542, acc.: 75.00%] [G loss: 0.967277]\n",
      "1486 [D loss: 0.588952, acc.: 73.44%] [G loss: 0.958453]\n",
      "1487 [D loss: 0.562437, acc.: 68.75%] [G loss: 0.956795]\n",
      "1488 [D loss: 0.561216, acc.: 78.12%] [G loss: 0.971437]\n",
      "1489 [D loss: 0.551929, acc.: 76.56%] [G loss: 1.056683]\n",
      "1490 [D loss: 0.586185, acc.: 64.06%] [G loss: 1.025035]\n",
      "1491 [D loss: 0.589737, acc.: 67.19%] [G loss: 1.089885]\n",
      "1492 [D loss: 0.550081, acc.: 75.00%] [G loss: 0.996794]\n",
      "1493 [D loss: 0.531013, acc.: 79.69%] [G loss: 0.990680]\n",
      "1494 [D loss: 0.594292, acc.: 68.75%] [G loss: 0.975125]\n",
      "1495 [D loss: 0.609395, acc.: 65.62%] [G loss: 0.992785]\n",
      "1496 [D loss: 0.583545, acc.: 67.19%] [G loss: 1.005543]\n",
      "1497 [D loss: 0.554642, acc.: 76.56%] [G loss: 0.899810]\n",
      "1498 [D loss: 0.590298, acc.: 71.88%] [G loss: 0.954608]\n",
      "1499 [D loss: 0.581728, acc.: 73.44%] [G loss: 0.973179]\n",
      "1500 [D loss: 0.626138, acc.: 60.94%] [G loss: 1.012308]\n",
      "1501 [D loss: 0.598495, acc.: 78.12%] [G loss: 0.921890]\n",
      "1502 [D loss: 0.629871, acc.: 64.06%] [G loss: 0.936889]\n",
      "1503 [D loss: 0.548306, acc.: 82.81%] [G loss: 0.847813]\n",
      "1504 [D loss: 0.567017, acc.: 73.44%] [G loss: 0.917670]\n",
      "1505 [D loss: 0.571282, acc.: 70.31%] [G loss: 0.959542]\n",
      "1506 [D loss: 0.549694, acc.: 79.69%] [G loss: 0.985649]\n",
      "1507 [D loss: 0.577171, acc.: 76.56%] [G loss: 1.090422]\n",
      "1508 [D loss: 0.582383, acc.: 70.31%] [G loss: 1.018210]\n",
      "1509 [D loss: 0.534047, acc.: 81.25%] [G loss: 0.946529]\n",
      "1510 [D loss: 0.554225, acc.: 79.69%] [G loss: 0.955534]\n",
      "1511 [D loss: 0.595235, acc.: 70.31%] [G loss: 0.957898]\n",
      "1512 [D loss: 0.591033, acc.: 70.31%] [G loss: 0.916682]\n",
      "1513 [D loss: 0.579880, acc.: 67.19%] [G loss: 0.964886]\n",
      "1514 [D loss: 0.548861, acc.: 81.25%] [G loss: 1.021719]\n",
      "1515 [D loss: 0.561317, acc.: 75.00%] [G loss: 1.029828]\n",
      "1516 [D loss: 0.582738, acc.: 76.56%] [G loss: 0.938335]\n",
      "1517 [D loss: 0.534972, acc.: 76.56%] [G loss: 0.973385]\n",
      "1518 [D loss: 0.589646, acc.: 71.88%] [G loss: 0.930963]\n",
      "1519 [D loss: 0.601127, acc.: 70.31%] [G loss: 0.983482]\n",
      "1520 [D loss: 0.595403, acc.: 73.44%] [G loss: 1.003549]\n",
      "1521 [D loss: 0.575891, acc.: 71.88%] [G loss: 0.932160]\n",
      "1522 [D loss: 0.591722, acc.: 65.62%] [G loss: 0.929576]\n",
      "1523 [D loss: 0.593403, acc.: 70.31%] [G loss: 0.993340]\n",
      "1524 [D loss: 0.546950, acc.: 75.00%] [G loss: 0.970020]\n",
      "1525 [D loss: 0.605947, acc.: 67.19%] [G loss: 1.046882]\n",
      "1526 [D loss: 0.585172, acc.: 68.75%] [G loss: 0.970601]\n",
      "1527 [D loss: 0.673993, acc.: 60.94%] [G loss: 0.923011]\n",
      "1528 [D loss: 0.499970, acc.: 78.12%] [G loss: 1.008891]\n",
      "1529 [D loss: 0.638221, acc.: 59.38%] [G loss: 0.935896]\n",
      "1530 [D loss: 0.576737, acc.: 70.31%] [G loss: 0.980138]\n",
      "1531 [D loss: 0.546419, acc.: 82.81%] [G loss: 0.981352]\n",
      "1532 [D loss: 0.663615, acc.: 59.38%] [G loss: 0.990501]\n",
      "1533 [D loss: 0.573241, acc.: 70.31%] [G loss: 0.963470]\n",
      "1534 [D loss: 0.594524, acc.: 71.88%] [G loss: 0.928348]\n",
      "1535 [D loss: 0.590072, acc.: 70.31%] [G loss: 0.935363]\n",
      "1536 [D loss: 0.538459, acc.: 71.88%] [G loss: 0.884805]\n",
      "1537 [D loss: 0.579079, acc.: 70.31%] [G loss: 0.981136]\n",
      "1538 [D loss: 0.530056, acc.: 75.00%] [G loss: 0.949643]\n",
      "1539 [D loss: 0.527663, acc.: 82.81%] [G loss: 0.985307]\n",
      "1540 [D loss: 0.651914, acc.: 60.94%] [G loss: 0.886113]\n",
      "1541 [D loss: 0.589113, acc.: 65.62%] [G loss: 0.898482]\n",
      "1542 [D loss: 0.571421, acc.: 75.00%] [G loss: 0.915613]\n",
      "1543 [D loss: 0.614383, acc.: 64.06%] [G loss: 0.942270]\n",
      "1544 [D loss: 0.581540, acc.: 64.06%] [G loss: 0.974357]\n",
      "1545 [D loss: 0.546964, acc.: 75.00%] [G loss: 0.981934]\n",
      "1546 [D loss: 0.526873, acc.: 78.12%] [G loss: 0.967502]\n",
      "1547 [D loss: 0.601964, acc.: 65.62%] [G loss: 1.024480]\n",
      "1548 [D loss: 0.601708, acc.: 65.62%] [G loss: 0.963114]\n",
      "1549 [D loss: 0.602519, acc.: 68.75%] [G loss: 0.978817]\n",
      "1550 [D loss: 0.586629, acc.: 76.56%] [G loss: 0.992778]\n",
      "1551 [D loss: 0.562622, acc.: 75.00%] [G loss: 0.970549]\n",
      "1552 [D loss: 0.592554, acc.: 65.62%] [G loss: 1.032785]\n",
      "1553 [D loss: 0.571732, acc.: 75.00%] [G loss: 0.945085]\n",
      "1554 [D loss: 0.605327, acc.: 70.31%] [G loss: 0.995746]\n",
      "1555 [D loss: 0.558861, acc.: 75.00%] [G loss: 0.999672]\n",
      "1556 [D loss: 0.568360, acc.: 78.12%] [G loss: 1.050252]\n",
      "1557 [D loss: 0.587306, acc.: 75.00%] [G loss: 1.038404]\n",
      "1558 [D loss: 0.517778, acc.: 82.81%] [G loss: 1.005188]\n",
      "1559 [D loss: 0.533425, acc.: 79.69%] [G loss: 0.870960]\n",
      "1560 [D loss: 0.599383, acc.: 70.31%] [G loss: 0.977807]\n",
      "1561 [D loss: 0.519280, acc.: 81.25%] [G loss: 0.959004]\n",
      "1562 [D loss: 0.563779, acc.: 75.00%] [G loss: 0.934523]\n",
      "1563 [D loss: 0.508031, acc.: 82.81%] [G loss: 0.922017]\n",
      "1564 [D loss: 0.651532, acc.: 62.50%] [G loss: 0.892756]\n",
      "1565 [D loss: 0.599787, acc.: 65.62%] [G loss: 0.983664]\n",
      "1566 [D loss: 0.539967, acc.: 71.88%] [G loss: 1.037478]\n",
      "1567 [D loss: 0.561848, acc.: 67.19%] [G loss: 1.021524]\n",
      "1568 [D loss: 0.572070, acc.: 67.19%] [G loss: 0.944722]\n",
      "1569 [D loss: 0.551343, acc.: 71.88%] [G loss: 0.966863]\n",
      "1570 [D loss: 0.601913, acc.: 71.88%] [G loss: 0.986495]\n",
      "1571 [D loss: 0.602261, acc.: 73.44%] [G loss: 0.881963]\n",
      "1572 [D loss: 0.513740, acc.: 81.25%] [G loss: 1.002658]\n",
      "1573 [D loss: 0.610809, acc.: 64.06%] [G loss: 0.972423]\n",
      "1574 [D loss: 0.555428, acc.: 75.00%] [G loss: 0.974522]\n",
      "1575 [D loss: 0.596704, acc.: 76.56%] [G loss: 0.990652]\n",
      "1576 [D loss: 0.488085, acc.: 81.25%] [G loss: 0.979200]\n",
      "1577 [D loss: 0.576747, acc.: 68.75%] [G loss: 1.110220]\n",
      "1578 [D loss: 0.607425, acc.: 68.75%] [G loss: 0.972007]\n",
      "1579 [D loss: 0.560280, acc.: 71.88%] [G loss: 0.979175]\n",
      "1580 [D loss: 0.562332, acc.: 73.44%] [G loss: 0.928047]\n",
      "1581 [D loss: 0.614039, acc.: 59.38%] [G loss: 0.899936]\n",
      "1582 [D loss: 0.596835, acc.: 70.31%] [G loss: 0.969913]\n",
      "1583 [D loss: 0.596539, acc.: 68.75%] [G loss: 0.929899]\n",
      "1584 [D loss: 0.553414, acc.: 75.00%] [G loss: 0.953829]\n",
      "1585 [D loss: 0.560605, acc.: 73.44%] [G loss: 0.954754]\n",
      "1586 [D loss: 0.576602, acc.: 67.19%] [G loss: 0.980131]\n",
      "1587 [D loss: 0.586238, acc.: 70.31%] [G loss: 0.984193]\n",
      "1588 [D loss: 0.590925, acc.: 75.00%] [G loss: 0.967396]\n",
      "1589 [D loss: 0.563316, acc.: 73.44%] [G loss: 0.991636]\n",
      "1590 [D loss: 0.604815, acc.: 67.19%] [G loss: 0.915471]\n",
      "1591 [D loss: 0.570645, acc.: 71.88%] [G loss: 0.979938]\n",
      "1592 [D loss: 0.580635, acc.: 75.00%] [G loss: 0.965694]\n",
      "1593 [D loss: 0.624883, acc.: 62.50%] [G loss: 0.944201]\n",
      "1594 [D loss: 0.597832, acc.: 67.19%] [G loss: 0.960139]\n",
      "1595 [D loss: 0.555118, acc.: 81.25%] [G loss: 1.006944]\n",
      "1596 [D loss: 0.545419, acc.: 81.25%] [G loss: 0.919606]\n",
      "1597 [D loss: 0.645019, acc.: 62.50%] [G loss: 0.989897]\n",
      "1598 [D loss: 0.552139, acc.: 73.44%] [G loss: 0.991760]\n",
      "1599 [D loss: 0.607949, acc.: 62.50%] [G loss: 0.928983]\n",
      "1600 [D loss: 0.562564, acc.: 68.75%] [G loss: 0.985638]\n",
      "1601 [D loss: 0.599298, acc.: 70.31%] [G loss: 0.956693]\n",
      "1602 [D loss: 0.608106, acc.: 60.94%] [G loss: 0.953051]\n",
      "1603 [D loss: 0.546903, acc.: 75.00%] [G loss: 1.028429]\n",
      "1604 [D loss: 0.598263, acc.: 70.31%] [G loss: 0.972412]\n",
      "1605 [D loss: 0.505452, acc.: 82.81%] [G loss: 0.946504]\n",
      "1606 [D loss: 0.605131, acc.: 64.06%] [G loss: 0.990874]\n",
      "1607 [D loss: 0.604825, acc.: 71.88%] [G loss: 1.003719]\n",
      "1608 [D loss: 0.523891, acc.: 81.25%] [G loss: 0.978822]\n",
      "1609 [D loss: 0.502737, acc.: 78.12%] [G loss: 0.946858]\n",
      "1610 [D loss: 0.525009, acc.: 79.69%] [G loss: 1.009081]\n",
      "1611 [D loss: 0.630012, acc.: 60.94%] [G loss: 1.039528]\n",
      "1612 [D loss: 0.615357, acc.: 62.50%] [G loss: 1.059241]\n",
      "1613 [D loss: 0.590104, acc.: 68.75%] [G loss: 1.012718]\n",
      "1614 [D loss: 0.644028, acc.: 64.06%] [G loss: 0.982831]\n",
      "1615 [D loss: 0.544887, acc.: 79.69%] [G loss: 0.909071]\n",
      "1616 [D loss: 0.611784, acc.: 62.50%] [G loss: 0.957798]\n",
      "1617 [D loss: 0.623399, acc.: 65.62%] [G loss: 0.955005]\n",
      "1618 [D loss: 0.597148, acc.: 71.88%] [G loss: 0.994924]\n",
      "1619 [D loss: 0.559027, acc.: 76.56%] [G loss: 0.936594]\n",
      "1620 [D loss: 0.630323, acc.: 65.62%] [G loss: 0.906936]\n",
      "1621 [D loss: 0.551957, acc.: 73.44%] [G loss: 0.941654]\n",
      "1622 [D loss: 0.545272, acc.: 73.44%] [G loss: 0.913095]\n",
      "1623 [D loss: 0.589597, acc.: 67.19%] [G loss: 0.984505]\n",
      "1624 [D loss: 0.567013, acc.: 73.44%] [G loss: 0.951725]\n",
      "1625 [D loss: 0.618311, acc.: 65.62%] [G loss: 0.930790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1626 [D loss: 0.591902, acc.: 62.50%] [G loss: 0.992187]\n",
      "1627 [D loss: 0.607487, acc.: 67.19%] [G loss: 0.902123]\n",
      "1628 [D loss: 0.603732, acc.: 71.88%] [G loss: 0.893150]\n",
      "1629 [D loss: 0.639702, acc.: 65.62%] [G loss: 0.927787]\n",
      "1630 [D loss: 0.591302, acc.: 70.31%] [G loss: 0.969623]\n",
      "1631 [D loss: 0.563718, acc.: 84.38%] [G loss: 0.848459]\n",
      "1632 [D loss: 0.637053, acc.: 62.50%] [G loss: 0.900678]\n",
      "1633 [D loss: 0.579904, acc.: 70.31%] [G loss: 0.890543]\n",
      "1634 [D loss: 0.639051, acc.: 62.50%] [G loss: 0.976864]\n",
      "1635 [D loss: 0.638379, acc.: 56.25%] [G loss: 0.903891]\n",
      "1636 [D loss: 0.608658, acc.: 60.94%] [G loss: 0.939068]\n",
      "1637 [D loss: 0.588955, acc.: 76.56%] [G loss: 0.977407]\n",
      "1638 [D loss: 0.562483, acc.: 79.69%] [G loss: 0.974290]\n",
      "1639 [D loss: 0.537820, acc.: 70.31%] [G loss: 1.011745]\n",
      "1640 [D loss: 0.525245, acc.: 78.12%] [G loss: 0.929153]\n",
      "1641 [D loss: 0.618551, acc.: 67.19%] [G loss: 0.983297]\n",
      "1642 [D loss: 0.560727, acc.: 79.69%] [G loss: 0.961790]\n",
      "1643 [D loss: 0.586281, acc.: 67.19%] [G loss: 0.888763]\n",
      "1644 [D loss: 0.553252, acc.: 78.12%] [G loss: 0.950939]\n",
      "1645 [D loss: 0.510189, acc.: 81.25%] [G loss: 0.986625]\n",
      "1646 [D loss: 0.534392, acc.: 79.69%] [G loss: 0.975789]\n",
      "1647 [D loss: 0.577429, acc.: 71.88%] [G loss: 0.994374]\n",
      "1648 [D loss: 0.556670, acc.: 70.31%] [G loss: 0.978790]\n",
      "1649 [D loss: 0.590357, acc.: 70.31%] [G loss: 0.938173]\n",
      "1650 [D loss: 0.527998, acc.: 73.44%] [G loss: 1.023313]\n",
      "1651 [D loss: 0.635616, acc.: 62.50%] [G loss: 0.962201]\n",
      "1652 [D loss: 0.577926, acc.: 73.44%] [G loss: 0.935002]\n",
      "1653 [D loss: 0.558577, acc.: 70.31%] [G loss: 0.925482]\n",
      "1654 [D loss: 0.572762, acc.: 70.31%] [G loss: 0.862924]\n",
      "1655 [D loss: 0.573657, acc.: 73.44%] [G loss: 0.919952]\n",
      "1656 [D loss: 0.534249, acc.: 78.12%] [G loss: 0.891225]\n",
      "1657 [D loss: 0.575289, acc.: 71.88%] [G loss: 0.900059]\n",
      "1658 [D loss: 0.534821, acc.: 73.44%] [G loss: 0.948882]\n",
      "1659 [D loss: 0.596261, acc.: 68.75%] [G loss: 0.892699]\n",
      "1660 [D loss: 0.537914, acc.: 76.56%] [G loss: 0.920199]\n",
      "1661 [D loss: 0.604149, acc.: 62.50%] [G loss: 0.912382]\n",
      "1662 [D loss: 0.551778, acc.: 78.12%] [G loss: 0.973775]\n",
      "1663 [D loss: 0.566844, acc.: 73.44%] [G loss: 1.030195]\n",
      "1664 [D loss: 0.579398, acc.: 68.75%] [G loss: 0.973587]\n",
      "1665 [D loss: 0.576119, acc.: 68.75%] [G loss: 1.008050]\n",
      "1666 [D loss: 0.544615, acc.: 70.31%] [G loss: 1.091882]\n",
      "1667 [D loss: 0.645498, acc.: 56.25%] [G loss: 1.018253]\n",
      "1668 [D loss: 0.653225, acc.: 59.38%] [G loss: 0.914628]\n",
      "1669 [D loss: 0.615349, acc.: 62.50%] [G loss: 0.898916]\n",
      "1670 [D loss: 0.574473, acc.: 78.12%] [G loss: 0.907099]\n",
      "1671 [D loss: 0.582345, acc.: 70.31%] [G loss: 0.954179]\n",
      "1672 [D loss: 0.608560, acc.: 71.88%] [G loss: 0.920115]\n",
      "1673 [D loss: 0.538438, acc.: 79.69%] [G loss: 0.950668]\n",
      "1674 [D loss: 0.556914, acc.: 78.12%] [G loss: 0.978669]\n",
      "1675 [D loss: 0.633104, acc.: 60.94%] [G loss: 1.006773]\n",
      "1676 [D loss: 0.645879, acc.: 67.19%] [G loss: 0.969220]\n",
      "1677 [D loss: 0.607230, acc.: 68.75%] [G loss: 0.932613]\n",
      "1678 [D loss: 0.558742, acc.: 78.12%] [G loss: 0.927474]\n",
      "1679 [D loss: 0.540815, acc.: 73.44%] [G loss: 0.990355]\n",
      "1680 [D loss: 0.550595, acc.: 71.88%] [G loss: 0.928474]\n",
      "1681 [D loss: 0.589605, acc.: 76.56%] [G loss: 0.923448]\n",
      "1682 [D loss: 0.552428, acc.: 71.88%] [G loss: 0.931723]\n",
      "1683 [D loss: 0.582005, acc.: 68.75%] [G loss: 0.954470]\n",
      "1684 [D loss: 0.576651, acc.: 65.62%] [G loss: 0.911334]\n",
      "1685 [D loss: 0.633512, acc.: 71.88%] [G loss: 0.925516]\n",
      "1686 [D loss: 0.543589, acc.: 76.56%] [G loss: 0.956666]\n",
      "1687 [D loss: 0.548336, acc.: 78.12%] [G loss: 1.037749]\n",
      "1688 [D loss: 0.567091, acc.: 71.88%] [G loss: 1.019412]\n",
      "1689 [D loss: 0.593243, acc.: 70.31%] [G loss: 0.998413]\n",
      "1690 [D loss: 0.538663, acc.: 76.56%] [G loss: 0.935952]\n",
      "1691 [D loss: 0.555889, acc.: 81.25%] [G loss: 0.928810]\n",
      "1692 [D loss: 0.538130, acc.: 78.12%] [G loss: 1.003027]\n",
      "1693 [D loss: 0.536924, acc.: 84.38%] [G loss: 0.973320]\n",
      "1694 [D loss: 0.540651, acc.: 82.81%] [G loss: 0.894778]\n",
      "1695 [D loss: 0.636129, acc.: 68.75%] [G loss: 0.913284]\n",
      "1696 [D loss: 0.545970, acc.: 70.31%] [G loss: 0.998410]\n",
      "1697 [D loss: 0.576017, acc.: 68.75%] [G loss: 0.952803]\n",
      "1698 [D loss: 0.573432, acc.: 68.75%] [G loss: 1.048394]\n",
      "1699 [D loss: 0.639518, acc.: 62.50%] [G loss: 0.969972]\n",
      "1700 [D loss: 0.555627, acc.: 75.00%] [G loss: 0.915963]\n",
      "1701 [D loss: 0.591607, acc.: 71.88%] [G loss: 0.995598]\n",
      "1702 [D loss: 0.567478, acc.: 70.31%] [G loss: 0.953362]\n",
      "1703 [D loss: 0.584455, acc.: 68.75%] [G loss: 0.944625]\n",
      "1704 [D loss: 0.549841, acc.: 76.56%] [G loss: 1.070633]\n",
      "1705 [D loss: 0.621592, acc.: 64.06%] [G loss: 1.033455]\n",
      "1706 [D loss: 0.552105, acc.: 76.56%] [G loss: 1.039415]\n",
      "1707 [D loss: 0.542557, acc.: 82.81%] [G loss: 0.973021]\n",
      "1708 [D loss: 0.567036, acc.: 76.56%] [G loss: 0.949629]\n",
      "1709 [D loss: 0.560012, acc.: 79.69%] [G loss: 0.966660]\n",
      "1710 [D loss: 0.631577, acc.: 67.19%] [G loss: 0.931355]\n",
      "1711 [D loss: 0.621381, acc.: 65.62%] [G loss: 1.019214]\n",
      "1712 [D loss: 0.587832, acc.: 73.44%] [G loss: 0.971261]\n",
      "1713 [D loss: 0.563705, acc.: 71.88%] [G loss: 0.940946]\n",
      "1714 [D loss: 0.552361, acc.: 81.25%] [G loss: 0.989247]\n",
      "1715 [D loss: 0.634457, acc.: 60.94%] [G loss: 0.938232]\n",
      "1716 [D loss: 0.617437, acc.: 64.06%] [G loss: 0.946186]\n",
      "1717 [D loss: 0.593745, acc.: 75.00%] [G loss: 0.972446]\n",
      "1718 [D loss: 0.537752, acc.: 81.25%] [G loss: 0.989284]\n",
      "1719 [D loss: 0.556263, acc.: 75.00%] [G loss: 1.020101]\n",
      "1720 [D loss: 0.566366, acc.: 78.12%] [G loss: 1.011166]\n",
      "1721 [D loss: 0.611153, acc.: 67.19%] [G loss: 0.938994]\n",
      "1722 [D loss: 0.589392, acc.: 68.75%] [G loss: 0.924666]\n",
      "1723 [D loss: 0.577047, acc.: 67.19%] [G loss: 0.890952]\n",
      "1724 [D loss: 0.567919, acc.: 75.00%] [G loss: 0.903271]\n",
      "1725 [D loss: 0.487832, acc.: 82.81%] [G loss: 0.935641]\n",
      "1726 [D loss: 0.540151, acc.: 70.31%] [G loss: 1.010925]\n",
      "1727 [D loss: 0.603008, acc.: 64.06%] [G loss: 0.945278]\n",
      "1728 [D loss: 0.635822, acc.: 68.75%] [G loss: 0.906237]\n",
      "1729 [D loss: 0.529841, acc.: 82.81%] [G loss: 0.941805]\n",
      "1730 [D loss: 0.556004, acc.: 73.44%] [G loss: 0.971346]\n",
      "1731 [D loss: 0.568169, acc.: 70.31%] [G loss: 0.913749]\n",
      "1732 [D loss: 0.600245, acc.: 68.75%] [G loss: 0.941262]\n",
      "1733 [D loss: 0.556505, acc.: 70.31%] [G loss: 0.976507]\n",
      "1734 [D loss: 0.545535, acc.: 75.00%] [G loss: 0.976543]\n",
      "1735 [D loss: 0.500883, acc.: 79.69%] [G loss: 0.936553]\n",
      "1736 [D loss: 0.568145, acc.: 75.00%] [G loss: 0.970071]\n",
      "1737 [D loss: 0.607599, acc.: 65.62%] [G loss: 0.946979]\n",
      "1738 [D loss: 0.598159, acc.: 62.50%] [G loss: 0.956998]\n",
      "1739 [D loss: 0.577828, acc.: 75.00%] [G loss: 0.915068]\n",
      "1740 [D loss: 0.566905, acc.: 75.00%] [G loss: 0.935216]\n",
      "1741 [D loss: 0.552395, acc.: 73.44%] [G loss: 0.944168]\n",
      "1742 [D loss: 0.591710, acc.: 67.19%] [G loss: 0.846680]\n",
      "1743 [D loss: 0.527286, acc.: 78.12%] [G loss: 0.962924]\n",
      "1744 [D loss: 0.535314, acc.: 70.31%] [G loss: 1.018284]\n",
      "1745 [D loss: 0.551083, acc.: 78.12%] [G loss: 0.991395]\n",
      "1746 [D loss: 0.590042, acc.: 70.31%] [G loss: 1.032750]\n",
      "1747 [D loss: 0.609833, acc.: 68.75%] [G loss: 1.029319]\n",
      "1748 [D loss: 0.648417, acc.: 64.06%] [G loss: 0.950741]\n",
      "1749 [D loss: 0.578484, acc.: 75.00%] [G loss: 0.985866]\n",
      "1750 [D loss: 0.582527, acc.: 68.75%] [G loss: 1.024474]\n",
      "1751 [D loss: 0.546367, acc.: 78.12%] [G loss: 1.005871]\n",
      "1752 [D loss: 0.589042, acc.: 67.19%] [G loss: 0.945254]\n",
      "1753 [D loss: 0.569294, acc.: 81.25%] [G loss: 1.006068]\n",
      "1754 [D loss: 0.518943, acc.: 78.12%] [G loss: 0.964736]\n",
      "1755 [D loss: 0.578824, acc.: 75.00%] [G loss: 0.901902]\n",
      "1756 [D loss: 0.556226, acc.: 68.75%] [G loss: 0.960957]\n",
      "1757 [D loss: 0.636161, acc.: 64.06%] [G loss: 0.885835]\n",
      "1758 [D loss: 0.558135, acc.: 62.50%] [G loss: 0.852889]\n",
      "1759 [D loss: 0.584376, acc.: 65.62%] [G loss: 0.907281]\n",
      "1760 [D loss: 0.563978, acc.: 70.31%] [G loss: 0.967936]\n",
      "1761 [D loss: 0.565178, acc.: 68.75%] [G loss: 1.010993]\n",
      "1762 [D loss: 0.606027, acc.: 65.62%] [G loss: 0.965203]\n",
      "1763 [D loss: 0.610825, acc.: 70.31%] [G loss: 1.028474]\n",
      "1764 [D loss: 0.540685, acc.: 76.56%] [G loss: 0.983736]\n",
      "1765 [D loss: 0.551662, acc.: 75.00%] [G loss: 0.974316]\n",
      "1766 [D loss: 0.565859, acc.: 73.44%] [G loss: 1.058175]\n",
      "1767 [D loss: 0.580189, acc.: 76.56%] [G loss: 0.983587]\n",
      "1768 [D loss: 0.592185, acc.: 62.50%] [G loss: 0.949526]\n",
      "1769 [D loss: 0.540372, acc.: 76.56%] [G loss: 1.008835]\n",
      "1770 [D loss: 0.610533, acc.: 64.06%] [G loss: 0.940694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1771 [D loss: 0.557884, acc.: 70.31%] [G loss: 0.991418]\n",
      "1772 [D loss: 0.568233, acc.: 73.44%] [G loss: 0.998775]\n",
      "1773 [D loss: 0.549352, acc.: 75.00%] [G loss: 1.000208]\n",
      "1774 [D loss: 0.595664, acc.: 64.06%] [G loss: 0.977616]\n",
      "1775 [D loss: 0.551456, acc.: 82.81%] [G loss: 0.916379]\n",
      "1776 [D loss: 0.550941, acc.: 71.88%] [G loss: 1.025513]\n",
      "1777 [D loss: 0.562603, acc.: 79.69%] [G loss: 1.013260]\n",
      "1778 [D loss: 0.500493, acc.: 85.94%] [G loss: 0.976858]\n",
      "1779 [D loss: 0.530908, acc.: 76.56%] [G loss: 1.059787]\n",
      "1780 [D loss: 0.540470, acc.: 71.88%] [G loss: 1.099471]\n",
      "1781 [D loss: 0.636773, acc.: 60.94%] [G loss: 0.968457]\n",
      "1782 [D loss: 0.607255, acc.: 65.62%] [G loss: 0.934516]\n",
      "1783 [D loss: 0.538161, acc.: 78.12%] [G loss: 0.890167]\n",
      "1784 [D loss: 0.527920, acc.: 76.56%] [G loss: 0.954395]\n",
      "1785 [D loss: 0.571010, acc.: 70.31%] [G loss: 1.038659]\n",
      "1786 [D loss: 0.643720, acc.: 68.75%] [G loss: 1.081825]\n",
      "1787 [D loss: 0.598479, acc.: 67.19%] [G loss: 0.992171]\n",
      "1788 [D loss: 0.547508, acc.: 76.56%] [G loss: 1.033035]\n",
      "1789 [D loss: 0.518909, acc.: 81.25%] [G loss: 0.961069]\n",
      "1790 [D loss: 0.524713, acc.: 79.69%] [G loss: 1.122801]\n",
      "1791 [D loss: 0.662895, acc.: 60.94%] [G loss: 0.968055]\n",
      "1792 [D loss: 0.533869, acc.: 73.44%] [G loss: 0.937529]\n",
      "1793 [D loss: 0.580175, acc.: 76.56%] [G loss: 0.925847]\n",
      "1794 [D loss: 0.546425, acc.: 82.81%] [G loss: 0.976806]\n",
      "1795 [D loss: 0.558952, acc.: 68.75%] [G loss: 0.921499]\n",
      "1796 [D loss: 0.564783, acc.: 65.62%] [G loss: 0.954360]\n",
      "1797 [D loss: 0.603827, acc.: 73.44%] [G loss: 0.898272]\n",
      "1798 [D loss: 0.597047, acc.: 68.75%] [G loss: 0.972390]\n",
      "1799 [D loss: 0.574787, acc.: 70.31%] [G loss: 0.972201]\n",
      "1800 [D loss: 0.558216, acc.: 70.31%] [G loss: 0.917348]\n",
      "1801 [D loss: 0.615325, acc.: 65.62%] [G loss: 1.013370]\n",
      "1802 [D loss: 0.592143, acc.: 68.75%] [G loss: 0.943777]\n",
      "1803 [D loss: 0.534364, acc.: 76.56%] [G loss: 0.924301]\n",
      "1804 [D loss: 0.585190, acc.: 68.75%] [G loss: 1.038439]\n",
      "1805 [D loss: 0.534230, acc.: 73.44%] [G loss: 0.980799]\n",
      "1806 [D loss: 0.572001, acc.: 73.44%] [G loss: 0.947599]\n",
      "1807 [D loss: 0.598654, acc.: 67.19%] [G loss: 0.877255]\n",
      "1808 [D loss: 0.523479, acc.: 78.12%] [G loss: 1.020545]\n",
      "1809 [D loss: 0.501196, acc.: 81.25%] [G loss: 1.010107]\n",
      "1810 [D loss: 0.509678, acc.: 82.81%] [G loss: 0.990601]\n",
      "1811 [D loss: 0.573748, acc.: 70.31%] [G loss: 0.964654]\n",
      "1812 [D loss: 0.609080, acc.: 71.88%] [G loss: 0.986400]\n",
      "1813 [D loss: 0.531131, acc.: 82.81%] [G loss: 0.936406]\n",
      "1814 [D loss: 0.550531, acc.: 78.12%] [G loss: 1.011272]\n",
      "1815 [D loss: 0.558793, acc.: 73.44%] [G loss: 0.972711]\n",
      "1816 [D loss: 0.583938, acc.: 70.31%] [G loss: 0.956805]\n",
      "1817 [D loss: 0.651381, acc.: 65.62%] [G loss: 0.891874]\n",
      "1818 [D loss: 0.544006, acc.: 78.12%] [G loss: 1.019224]\n",
      "1819 [D loss: 0.591402, acc.: 73.44%] [G loss: 0.886101]\n",
      "1820 [D loss: 0.628575, acc.: 56.25%] [G loss: 1.014450]\n",
      "1821 [D loss: 0.550597, acc.: 76.56%] [G loss: 0.975089]\n",
      "1822 [D loss: 0.607022, acc.: 65.62%] [G loss: 1.014755]\n",
      "1823 [D loss: 0.587515, acc.: 73.44%] [G loss: 0.973808]\n",
      "1824 [D loss: 0.566359, acc.: 75.00%] [G loss: 0.965702]\n",
      "1825 [D loss: 0.530480, acc.: 84.38%] [G loss: 0.948572]\n",
      "1826 [D loss: 0.567400, acc.: 75.00%] [G loss: 0.976035]\n",
      "1827 [D loss: 0.556114, acc.: 78.12%] [G loss: 0.883175]\n",
      "1828 [D loss: 0.623921, acc.: 62.50%] [G loss: 1.004786]\n",
      "1829 [D loss: 0.597678, acc.: 65.62%] [G loss: 1.079741]\n",
      "1830 [D loss: 0.629469, acc.: 59.38%] [G loss: 1.032524]\n",
      "1831 [D loss: 0.527792, acc.: 75.00%] [G loss: 1.063540]\n",
      "1832 [D loss: 0.590203, acc.: 70.31%] [G loss: 1.023696]\n",
      "1833 [D loss: 0.570156, acc.: 73.44%] [G loss: 0.942775]\n",
      "1834 [D loss: 0.556198, acc.: 79.69%] [G loss: 0.871723]\n",
      "1835 [D loss: 0.540656, acc.: 78.12%] [G loss: 1.037240]\n",
      "1836 [D loss: 0.558297, acc.: 70.31%] [G loss: 0.970231]\n",
      "1837 [D loss: 0.587529, acc.: 75.00%] [G loss: 0.986535]\n",
      "1838 [D loss: 0.693188, acc.: 56.25%] [G loss: 0.888484]\n",
      "1839 [D loss: 0.612622, acc.: 71.88%] [G loss: 0.923329]\n",
      "1840 [D loss: 0.579470, acc.: 70.31%] [G loss: 1.005786]\n",
      "1841 [D loss: 0.544895, acc.: 75.00%] [G loss: 1.045492]\n",
      "1842 [D loss: 0.580444, acc.: 68.75%] [G loss: 1.025500]\n",
      "1843 [D loss: 0.559449, acc.: 78.12%] [G loss: 1.072870]\n",
      "1844 [D loss: 0.539168, acc.: 76.56%] [G loss: 0.992041]\n",
      "1845 [D loss: 0.592342, acc.: 67.19%] [G loss: 1.026011]\n",
      "1846 [D loss: 0.633223, acc.: 65.62%] [G loss: 0.886148]\n",
      "1847 [D loss: 0.556965, acc.: 70.31%] [G loss: 1.028650]\n",
      "1848 [D loss: 0.559403, acc.: 81.25%] [G loss: 1.021223]\n",
      "1849 [D loss: 0.580171, acc.: 76.56%] [G loss: 1.023490]\n",
      "1850 [D loss: 0.605962, acc.: 60.94%] [G loss: 0.984895]\n",
      "1851 [D loss: 0.529095, acc.: 78.12%] [G loss: 1.020995]\n",
      "1852 [D loss: 0.636758, acc.: 59.38%] [G loss: 0.892085]\n",
      "1853 [D loss: 0.613686, acc.: 64.06%] [G loss: 0.919095]\n",
      "1854 [D loss: 0.647647, acc.: 64.06%] [G loss: 0.921064]\n",
      "1855 [D loss: 0.585686, acc.: 65.62%] [G loss: 0.961340]\n",
      "1856 [D loss: 0.658375, acc.: 53.12%] [G loss: 1.047368]\n",
      "1857 [D loss: 0.640270, acc.: 59.38%] [G loss: 1.077575]\n",
      "1858 [D loss: 0.577800, acc.: 67.19%] [G loss: 0.925803]\n",
      "1859 [D loss: 0.530379, acc.: 78.12%] [G loss: 1.033768]\n",
      "1860 [D loss: 0.536607, acc.: 73.44%] [G loss: 0.936431]\n",
      "1861 [D loss: 0.537180, acc.: 76.56%] [G loss: 0.974311]\n",
      "1862 [D loss: 0.612145, acc.: 71.88%] [G loss: 1.022137]\n",
      "1863 [D loss: 0.570907, acc.: 70.31%] [G loss: 0.902228]\n",
      "1864 [D loss: 0.538959, acc.: 71.88%] [G loss: 1.029720]\n",
      "1865 [D loss: 0.622969, acc.: 68.75%] [G loss: 1.040136]\n",
      "1866 [D loss: 0.584207, acc.: 68.75%] [G loss: 1.058204]\n",
      "1867 [D loss: 0.560784, acc.: 73.44%] [G loss: 1.049044]\n",
      "1868 [D loss: 0.574199, acc.: 73.44%] [G loss: 0.962702]\n",
      "1869 [D loss: 0.543527, acc.: 76.56%] [G loss: 1.062562]\n",
      "1870 [D loss: 0.601338, acc.: 65.62%] [G loss: 0.987961]\n",
      "1871 [D loss: 0.510819, acc.: 75.00%] [G loss: 1.053638]\n",
      "1872 [D loss: 0.531581, acc.: 76.56%] [G loss: 1.050359]\n",
      "1873 [D loss: 0.577410, acc.: 78.12%] [G loss: 1.086522]\n",
      "1874 [D loss: 0.573628, acc.: 71.88%] [G loss: 1.031526]\n",
      "1875 [D loss: 0.517151, acc.: 75.00%] [G loss: 1.159058]\n",
      "1876 [D loss: 0.576913, acc.: 62.50%] [G loss: 1.129026]\n",
      "1877 [D loss: 0.553198, acc.: 75.00%] [G loss: 1.100244]\n",
      "1878 [D loss: 0.605503, acc.: 65.62%] [G loss: 0.909391]\n",
      "1879 [D loss: 0.583034, acc.: 75.00%] [G loss: 0.992403]\n",
      "1880 [D loss: 0.527062, acc.: 78.12%] [G loss: 0.970492]\n",
      "1881 [D loss: 0.527421, acc.: 78.12%] [G loss: 0.966550]\n",
      "1882 [D loss: 0.533779, acc.: 76.56%] [G loss: 0.988205]\n",
      "1883 [D loss: 0.557459, acc.: 70.31%] [G loss: 0.946747]\n",
      "1884 [D loss: 0.532611, acc.: 78.12%] [G loss: 1.100395]\n",
      "1885 [D loss: 0.491925, acc.: 81.25%] [G loss: 1.058355]\n",
      "1886 [D loss: 0.491904, acc.: 79.69%] [G loss: 1.074530]\n",
      "1887 [D loss: 0.567616, acc.: 70.31%] [G loss: 1.054226]\n",
      "1888 [D loss: 0.547161, acc.: 70.31%] [G loss: 1.009187]\n",
      "1889 [D loss: 0.608988, acc.: 71.88%] [G loss: 1.018176]\n",
      "1890 [D loss: 0.524202, acc.: 79.69%] [G loss: 0.932997]\n",
      "1891 [D loss: 0.563746, acc.: 71.88%] [G loss: 0.953208]\n",
      "1892 [D loss: 0.574377, acc.: 71.88%] [G loss: 0.980642]\n",
      "1893 [D loss: 0.597217, acc.: 70.31%] [G loss: 1.026683]\n",
      "1894 [D loss: 0.536918, acc.: 78.12%] [G loss: 1.018096]\n",
      "1895 [D loss: 0.528498, acc.: 76.56%] [G loss: 0.949573]\n",
      "1896 [D loss: 0.606411, acc.: 65.62%] [G loss: 0.942488]\n",
      "1897 [D loss: 0.536737, acc.: 73.44%] [G loss: 1.051610]\n",
      "1898 [D loss: 0.560661, acc.: 68.75%] [G loss: 1.087827]\n",
      "1899 [D loss: 0.617165, acc.: 60.94%] [G loss: 0.966499]\n",
      "1900 [D loss: 0.594774, acc.: 68.75%] [G loss: 0.972121]\n",
      "1901 [D loss: 0.557727, acc.: 73.44%] [G loss: 0.950584]\n",
      "1902 [D loss: 0.565181, acc.: 70.31%] [G loss: 1.045093]\n",
      "1903 [D loss: 0.611808, acc.: 65.62%] [G loss: 0.918585]\n",
      "1904 [D loss: 0.553388, acc.: 73.44%] [G loss: 1.011144]\n",
      "1905 [D loss: 0.547698, acc.: 73.44%] [G loss: 0.970144]\n",
      "1906 [D loss: 0.622629, acc.: 67.19%] [G loss: 0.949735]\n",
      "1907 [D loss: 0.551961, acc.: 78.12%] [G loss: 0.902720]\n",
      "1908 [D loss: 0.557316, acc.: 73.44%] [G loss: 0.944413]\n",
      "1909 [D loss: 0.573529, acc.: 65.62%] [G loss: 0.946491]\n",
      "1910 [D loss: 0.599625, acc.: 67.19%] [G loss: 0.975752]\n",
      "1911 [D loss: 0.606767, acc.: 70.31%] [G loss: 0.990152]\n",
      "1912 [D loss: 0.561624, acc.: 76.56%] [G loss: 0.943956]\n",
      "1913 [D loss: 0.562973, acc.: 65.62%] [G loss: 0.981033]\n",
      "1914 [D loss: 0.556431, acc.: 76.56%] [G loss: 1.045218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1915 [D loss: 0.651792, acc.: 62.50%] [G loss: 0.912753]\n",
      "1916 [D loss: 0.552897, acc.: 68.75%] [G loss: 0.899102]\n",
      "1917 [D loss: 0.526605, acc.: 82.81%] [G loss: 0.929860]\n",
      "1918 [D loss: 0.637003, acc.: 60.94%] [G loss: 0.876256]\n",
      "1919 [D loss: 0.588693, acc.: 68.75%] [G loss: 0.966456]\n",
      "1920 [D loss: 0.565618, acc.: 68.75%] [G loss: 0.995472]\n",
      "1921 [D loss: 0.581453, acc.: 71.88%] [G loss: 0.968844]\n",
      "1922 [D loss: 0.590155, acc.: 68.75%] [G loss: 0.950567]\n",
      "1923 [D loss: 0.553632, acc.: 76.56%] [G loss: 0.961454]\n",
      "1924 [D loss: 0.574297, acc.: 67.19%] [G loss: 0.979249]\n",
      "1925 [D loss: 0.607689, acc.: 64.06%] [G loss: 0.959826]\n",
      "1926 [D loss: 0.573470, acc.: 73.44%] [G loss: 0.917557]\n",
      "1927 [D loss: 0.603241, acc.: 68.75%] [G loss: 0.930141]\n",
      "1928 [D loss: 0.568319, acc.: 67.19%] [G loss: 0.958533]\n",
      "1929 [D loss: 0.659379, acc.: 60.94%] [G loss: 0.985682]\n",
      "1930 [D loss: 0.581258, acc.: 70.31%] [G loss: 0.955161]\n",
      "1931 [D loss: 0.608677, acc.: 62.50%] [G loss: 1.005056]\n",
      "1932 [D loss: 0.533919, acc.: 76.56%] [G loss: 1.077994]\n",
      "1933 [D loss: 0.551518, acc.: 75.00%] [G loss: 0.995112]\n",
      "1934 [D loss: 0.486306, acc.: 78.12%] [G loss: 0.947583]\n",
      "1935 [D loss: 0.575515, acc.: 70.31%] [G loss: 0.913768]\n",
      "1936 [D loss: 0.643643, acc.: 68.75%] [G loss: 0.909460]\n",
      "1937 [D loss: 0.597012, acc.: 70.31%] [G loss: 1.038451]\n",
      "1938 [D loss: 0.579968, acc.: 70.31%] [G loss: 0.974563]\n",
      "1939 [D loss: 0.614035, acc.: 68.75%] [G loss: 0.962968]\n",
      "1940 [D loss: 0.609453, acc.: 65.62%] [G loss: 0.939547]\n",
      "1941 [D loss: 0.549656, acc.: 79.69%] [G loss: 1.066210]\n",
      "1942 [D loss: 0.606710, acc.: 64.06%] [G loss: 0.943384]\n",
      "1943 [D loss: 0.578642, acc.: 67.19%] [G loss: 0.952693]\n",
      "1944 [D loss: 0.676351, acc.: 51.56%] [G loss: 0.987232]\n",
      "1945 [D loss: 0.589867, acc.: 67.19%] [G loss: 0.936261]\n",
      "1946 [D loss: 0.607914, acc.: 62.50%] [G loss: 1.025334]\n",
      "1947 [D loss: 0.655095, acc.: 56.25%] [G loss: 0.996201]\n",
      "1948 [D loss: 0.496989, acc.: 84.38%] [G loss: 1.048980]\n",
      "1949 [D loss: 0.579914, acc.: 76.56%] [G loss: 0.969232]\n",
      "1950 [D loss: 0.595961, acc.: 75.00%] [G loss: 0.946650]\n",
      "1951 [D loss: 0.626455, acc.: 67.19%] [G loss: 0.983382]\n",
      "1952 [D loss: 0.539764, acc.: 78.12%] [G loss: 1.086460]\n",
      "1953 [D loss: 0.553087, acc.: 78.12%] [G loss: 0.999389]\n",
      "1954 [D loss: 0.619245, acc.: 68.75%] [G loss: 0.879318]\n",
      "1955 [D loss: 0.562541, acc.: 75.00%] [G loss: 1.110662]\n",
      "1956 [D loss: 0.528138, acc.: 79.69%] [G loss: 1.010958]\n",
      "1957 [D loss: 0.574998, acc.: 70.31%] [G loss: 0.891460]\n",
      "1958 [D loss: 0.584000, acc.: 75.00%] [G loss: 0.989138]\n",
      "1959 [D loss: 0.579034, acc.: 71.88%] [G loss: 0.952419]\n",
      "1960 [D loss: 0.599607, acc.: 67.19%] [G loss: 0.851206]\n",
      "1961 [D loss: 0.591019, acc.: 67.19%] [G loss: 1.047620]\n",
      "1962 [D loss: 0.630879, acc.: 64.06%] [G loss: 0.987333]\n",
      "1963 [D loss: 0.596214, acc.: 62.50%] [G loss: 1.036902]\n",
      "1964 [D loss: 0.599282, acc.: 68.75%] [G loss: 0.953346]\n",
      "1965 [D loss: 0.565623, acc.: 73.44%] [G loss: 0.960859]\n",
      "1966 [D loss: 0.556099, acc.: 78.12%] [G loss: 0.947829]\n",
      "1967 [D loss: 0.572725, acc.: 76.56%] [G loss: 0.952884]\n",
      "1968 [D loss: 0.602582, acc.: 68.75%] [G loss: 1.076368]\n",
      "1969 [D loss: 0.605983, acc.: 73.44%] [G loss: 0.993714]\n",
      "1970 [D loss: 0.541252, acc.: 76.56%] [G loss: 0.977902]\n",
      "1971 [D loss: 0.622104, acc.: 65.62%] [G loss: 0.960954]\n",
      "1972 [D loss: 0.535622, acc.: 79.69%] [G loss: 0.952813]\n",
      "1973 [D loss: 0.568758, acc.: 78.12%] [G loss: 0.963146]\n",
      "1974 [D loss: 0.524453, acc.: 75.00%] [G loss: 0.971322]\n",
      "1975 [D loss: 0.629955, acc.: 64.06%] [G loss: 0.997222]\n",
      "1976 [D loss: 0.644086, acc.: 56.25%] [G loss: 0.923714]\n",
      "1977 [D loss: 0.599308, acc.: 71.88%] [G loss: 0.966930]\n",
      "1978 [D loss: 0.615578, acc.: 60.94%] [G loss: 0.938865]\n",
      "1979 [D loss: 0.562211, acc.: 71.88%] [G loss: 1.047964]\n",
      "1980 [D loss: 0.549467, acc.: 76.56%] [G loss: 1.104894]\n",
      "1981 [D loss: 0.557143, acc.: 75.00%] [G loss: 1.046286]\n",
      "1982 [D loss: 0.564067, acc.: 76.56%] [G loss: 1.013136]\n",
      "1983 [D loss: 0.590605, acc.: 73.44%] [G loss: 0.973904]\n",
      "1984 [D loss: 0.593856, acc.: 67.19%] [G loss: 0.938876]\n",
      "1985 [D loss: 0.600332, acc.: 70.31%] [G loss: 0.923617]\n",
      "1986 [D loss: 0.609556, acc.: 65.62%] [G loss: 0.940871]\n",
      "1987 [D loss: 0.618653, acc.: 64.06%] [G loss: 0.989269]\n",
      "1988 [D loss: 0.594408, acc.: 67.19%] [G loss: 0.951994]\n",
      "1989 [D loss: 0.583452, acc.: 65.62%] [G loss: 0.926893]\n",
      "1990 [D loss: 0.525042, acc.: 75.00%] [G loss: 0.975559]\n",
      "1991 [D loss: 0.667016, acc.: 64.06%] [G loss: 0.911564]\n",
      "1992 [D loss: 0.607616, acc.: 70.31%] [G loss: 0.956816]\n",
      "1993 [D loss: 0.498676, acc.: 79.69%] [G loss: 0.937185]\n",
      "1994 [D loss: 0.534196, acc.: 76.56%] [G loss: 1.006318]\n",
      "1995 [D loss: 0.612262, acc.: 68.75%] [G loss: 0.993180]\n",
      "1996 [D loss: 0.553353, acc.: 73.44%] [G loss: 0.977045]\n",
      "1997 [D loss: 0.551519, acc.: 73.44%] [G loss: 1.042903]\n",
      "1998 [D loss: 0.616418, acc.: 65.62%] [G loss: 1.009758]\n",
      "1999 [D loss: 0.582550, acc.: 68.75%] [G loss: 1.003771]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gan = GAN()\n",
    "gan.train(epochs=2000, batch_size=32, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
